:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-af1294be-e148-4ff4-a470-798fa7d40ebd;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central
	found org.apache.kafka#kafka-clients;2.4.1 in central
	found com.github.luben#zstd-jni;1.4.4-3 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.7.5 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.0.0/spark-sql-kafka-0-10_2.12-3.0.0.jar ...
	[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0!spark-sql-kafka-0-10_2.12.jar (188ms)
downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.0.0/spark-token-provider-kafka-0-10_2.12-3.0.0.jar ...
	[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0!spark-token-provider-kafka-0-10_2.12.jar (93ms)
downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/2.4.1/kafka-clients-2.4.1.jar ...
	[SUCCESSFUL ] org.apache.kafka#kafka-clients;2.4.1!kafka-clients.jar (326ms)
downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.6.2/commons-pool2-2.6.2.jar ...
	[SUCCESSFUL ] org.apache.commons#commons-pool2;2.6.2!commons-pool2.jar (95ms)
downloading https://repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar ...
	[SUCCESSFUL ] org.spark-project.spark#unused;1.0.0!unused.jar (97ms)
downloading https://repo1.maven.org/maven2/com/github/luben/zstd-jni/1.4.4-3/zstd-jni-1.4.4-3.jar ...
	[SUCCESSFUL ] com.github.luben#zstd-jni;1.4.4-3!zstd-jni.jar (318ms)
downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar ...
	[SUCCESSFUL ] org.lz4#lz4-java;1.7.1!lz4-java.jar (122ms)
downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.7.5/snappy-java-1.1.7.5.jar ...
	[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.7.5!snappy-java.jar(bundle) (183ms)
downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar ...
	[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.30!slf4j-api.jar (235ms)
:: resolution report :: resolve 9794ms :: artifacts dl 1707ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.4-3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.7.5 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   9   |   9   |   0   ||   9   |   9   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-af1294be-e148-4ff4-a470-798fa7d40ebd
	confs: [default]
	9 artifacts copied, 0 already retrieved (10393kB/284ms)
22/06/11 17:03:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
python3: can't open file '/home/workspace/project/starter/sparkpykafkajoin.py': [Errno 2] No such file or directory
log4j:WARN No appenders could be found for logger (org.apache.spark.util.ShutdownHookManager).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-8c5780c4-3349-44ad-b357-558d5e3bcabc;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central
	found org.apache.kafka#kafka-clients;2.4.1 in central
	found com.github.luben#zstd-jni;1.4.4-3 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.7.5 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 368ms :: artifacts dl 41ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.4-3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.7.5 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-8c5780c4-3349-44ad-b357-558d5e3bcabc
	confs: [default]
	0 artifacts copied, 9 already retrieved (0kB/12ms)
22/06/11 17:12:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
python3: can't open file '/home/workspace/project/starter/sparkpykafkajoin.py': [Errno 2] No such file or directory
log4j:WARN No appenders could be found for logger (org.apache.spark.util.ShutdownHookManager).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-466a74b0-39d0-4c5c-8afb-4af1939141a1;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central
	found org.apache.kafka#kafka-clients;2.4.1 in central
	found com.github.luben#zstd-jni;1.4.4-3 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.7.5 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 377ms :: artifacts dl 42ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.4-3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.7.5 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-466a74b0-39d0-4c5c-8afb-4af1939141a1
	confs: [default]
	0 artifacts copied, 9 already retrieved (0kB/12ms)
22/06/11 17:12:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
python3: can't open file '/home/workspace/project/starter/sparkpykafkajoin.py': [Errno 2] No such file or directory
log4j:WARN No appenders could be found for logger (org.apache.spark.util.ShutdownHookManager).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-957125fc-1b45-48d9-a09f-08ad77310c73;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central
	found org.apache.kafka#kafka-clients;2.4.1 in central
	found com.github.luben#zstd-jni;1.4.4-3 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.7.5 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 356ms :: artifacts dl 39ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.4-3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.7.5 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-957125fc-1b45-48d9-a09f-08ad77310c73
	confs: [default]
	0 artifacts copied, 9 already retrieved (0kB/11ms)
22/06/11 17:15:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Traceback (most recent call last):
  File "/home/workspace/sparkpykafkajoin.py", line 50, in <module>
    spark.SparkContext.setLogLevel('WARN')
AttributeError: 'Builder' object has no attribute 'SparkContext'
log4j:WARN No appenders could be found for logger (org.apache.spark.util.ShutdownHookManager).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-c79a2768-c839-41e4-87fc-f40b30b23fc1;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central
	found org.apache.kafka#kafka-clients;2.4.1 in central
	found com.github.luben#zstd-jni;1.4.4-3 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.7.5 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 354ms :: artifacts dl 39ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.4-3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.7.5 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-c79a2768-c839-41e4-87fc-f40b30b23fc1
	confs: [default]
	0 artifacts copied, 9 already retrieved (0kB/12ms)
22/06/11 17:19:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/11 17:19:06 INFO SparkContext: Running Spark version 3.2.1
22/06/11 17:19:06 INFO ResourceUtils: ==============================================================
22/06/11 17:19:06 INFO ResourceUtils: No custom resources configured for spark.driver.
22/06/11 17:19:06 INFO ResourceUtils: ==============================================================
22/06/11 17:19:06 INFO SparkContext: Submitted application: Evaluate-Human-Balance
22/06/11 17:19:06 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/06/11 17:19:06 INFO ResourceProfile: Limiting resource is cpu
22/06/11 17:19:06 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/06/11 17:19:06 INFO SecurityManager: Changing view acls to: spark
22/06/11 17:19:06 INFO SecurityManager: Changing modify acls to: spark
22/06/11 17:19:06 INFO SecurityManager: Changing view acls groups to: 
22/06/11 17:19:06 INFO SecurityManager: Changing modify acls groups to: 
22/06/11 17:19:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
22/06/11 17:19:06 INFO Utils: Successfully started service 'sparkDriver' on port 37559.
22/06/11 17:19:07 INFO SparkEnv: Registering MapOutputTracker
22/06/11 17:19:07 INFO SparkEnv: Registering BlockManagerMaster
22/06/11 17:19:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/11 17:19:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/11 17:19:07 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/06/11 17:19:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-df4c2fbb-839b-439b-a35d-ecdaaae866a5
22/06/11 17:19:07 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/06/11 17:19:07 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/11 17:19:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/11 17:19:07 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://d86e382532b9:4040
22/06/11 17:19:07 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar at spark://d86e382532b9:37559/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar at spark://d86e382532b9:37559/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar at spark://d86e382532b9:37559/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://d86e382532b9:37559/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://d86e382532b9:37559/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar at spark://d86e382532b9:37559/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://d86e382532b9:37559/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar at spark://d86e382532b9:37559/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://d86e382532b9:37559/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:19:07 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:19:07 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:19:07 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:19:07 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:19:07 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar at file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:19:07 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:19:07 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar at file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:19:07 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:19:07 INFO Executor: Starting executor ID driver on host d86e382532b9
22/06/11 17:19:07 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:19:07 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:19:07 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:19:07 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:19:07 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:19:07 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:19:07 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:19:07 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:19:07 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:19:07 INFO Executor: Fetching spark://d86e382532b9:37559/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO TransportClientFactory: Successfully created connection to d86e382532b9/172.22.0.4:37559 after 20 ms (0 ms spent in bootstraps)
22/06/11 17:19:07 INFO Utils: Fetching spark://d86e382532b9:37559/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp591547619826851853.tmp
22/06/11 17:19:07 INFO Utils: /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp591547619826851853.tmp has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:19:07 INFO Executor: Adding file:/tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to class loader
22/06/11 17:19:07 INFO Executor: Fetching spark://d86e382532b9:37559/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Fetching spark://d86e382532b9:37559/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp2663564176979508309.tmp
22/06/11 17:19:07 INFO Utils: /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp2663564176979508309.tmp has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:19:07 INFO Executor: Adding file:/tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.slf4j_slf4j-api-1.7.30.jar to class loader
22/06/11 17:19:07 INFO Executor: Fetching spark://d86e382532b9:37559/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Fetching spark://d86e382532b9:37559/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp2635759523252171952.tmp
22/06/11 17:19:07 INFO Utils: /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp2635759523252171952.tmp has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:19:07 INFO Executor: Adding file:/tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.xerial.snappy_snappy-java-1.1.7.5.jar to class loader
22/06/11 17:19:07 INFO Executor: Fetching spark://d86e382532b9:37559/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Fetching spark://d86e382532b9:37559/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp8051131684206681128.tmp
22/06/11 17:19:07 INFO Utils: /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp8051131684206681128.tmp has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:19:07 INFO Executor: Adding file:/tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.apache.commons_commons-pool2-2.6.2.jar to class loader
22/06/11 17:19:07 INFO Executor: Fetching spark://d86e382532b9:37559/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Fetching spark://d86e382532b9:37559/jars/org.apache.kafka_kafka-clients-2.4.1.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp2754020361511696825.tmp
22/06/11 17:19:07 INFO Utils: /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp2754020361511696825.tmp has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:19:07 INFO Executor: Adding file:/tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.apache.kafka_kafka-clients-2.4.1.jar to class loader
22/06/11 17:19:07 INFO Executor: Fetching spark://d86e382532b9:37559/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Fetching spark://d86e382532b9:37559/jars/com.github.luben_zstd-jni-1.4.4-3.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp7080738433237519490.tmp
22/06/11 17:19:07 INFO Utils: /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp7080738433237519490.tmp has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:19:07 INFO Executor: Adding file:/tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/com.github.luben_zstd-jni-1.4.4-3.jar to class loader
22/06/11 17:19:07 INFO Executor: Fetching spark://d86e382532b9:37559/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Fetching spark://d86e382532b9:37559/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp5243189970522109630.tmp
22/06/11 17:19:07 INFO Utils: /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp5243189970522109630.tmp has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:19:07 INFO Executor: Adding file:/tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to class loader
22/06/11 17:19:07 INFO Executor: Fetching spark://d86e382532b9:37559/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Fetching spark://d86e382532b9:37559/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp8935370732550890779.tmp
22/06/11 17:19:07 INFO Utils: /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp8935370732550890779.tmp has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:19:07 INFO Executor: Adding file:/tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.lz4_lz4-java-1.7.1.jar to class loader
22/06/11 17:19:07 INFO Executor: Fetching spark://d86e382532b9:37559/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654967946702
22/06/11 17:19:07 INFO Utils: Fetching spark://d86e382532b9:37559/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp685838222202906595.tmp
22/06/11 17:19:07 INFO Utils: /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/fetchFileTemp685838222202906595.tmp has been previously copied to /tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:19:07 INFO Executor: Adding file:/tmp/spark-fbeaa841-8f2c-4dc7-8638-5416b571575b/userFiles-ebfa2392-1e93-4a47-bb10-d50d623ce0a5/org.spark-project.spark_unused-1.0.0.jar to class loader
22/06/11 17:19:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41589.
22/06/11 17:19:07 INFO NettyBlockTransferService: Server created on d86e382532b9:41589
22/06/11 17:19:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/11 17:19:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d86e382532b9, 41589, None)
22/06/11 17:19:07 INFO BlockManagerMasterEndpoint: Registering block manager d86e382532b9:41589 with 366.3 MiB RAM, BlockManagerId(driver, d86e382532b9, 41589, None)
22/06/11 17:19:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d86e382532b9, 41589, None)
22/06/11 17:19:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d86e382532b9, 41589, None)
22/06/11 17:19:08 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/06/11 17:19:08 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
Traceback (most recent call last):
  File "/home/workspace/sparkpykafkajoin.py", line 88, in <module>
    redisServerStreamingDF\
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 1659, in __getattr__
AttributeError: 'DataFrame' object has no attribute 'selet'
:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-a5e62d55-64f4-4c76-b4c7-7fe0af5eb093;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central
	found org.apache.kafka#kafka-clients;2.4.1 in central
	found com.github.luben#zstd-jni;1.4.4-3 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.7.5 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 417ms :: artifacts dl 51ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.4-3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.7.5 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-a5e62d55-64f4-4c76-b4c7-7fe0af5eb093
	confs: [default]
	0 artifacts copied, 9 already retrieved (0kB/10ms)
22/06/11 17:20:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/11 17:20:22 INFO SparkContext: Running Spark version 3.2.1
22/06/11 17:20:22 INFO ResourceUtils: ==============================================================
22/06/11 17:20:22 INFO ResourceUtils: No custom resources configured for spark.driver.
22/06/11 17:20:22 INFO ResourceUtils: ==============================================================
22/06/11 17:20:22 INFO SparkContext: Submitted application: Evaluate-Human-Balance
22/06/11 17:20:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/06/11 17:20:22 INFO ResourceProfile: Limiting resource is cpu
22/06/11 17:20:22 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/06/11 17:20:23 INFO SecurityManager: Changing view acls to: spark
22/06/11 17:20:23 INFO SecurityManager: Changing modify acls to: spark
22/06/11 17:20:23 INFO SecurityManager: Changing view acls groups to: 
22/06/11 17:20:23 INFO SecurityManager: Changing modify acls groups to: 
22/06/11 17:20:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
22/06/11 17:20:23 INFO Utils: Successfully started service 'sparkDriver' on port 39727.
22/06/11 17:20:23 INFO SparkEnv: Registering MapOutputTracker
22/06/11 17:20:23 INFO SparkEnv: Registering BlockManagerMaster
22/06/11 17:20:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/11 17:20:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/11 17:20:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/06/11 17:20:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d98853c4-a3be-4788-bde2-f0bdeeb9828d
22/06/11 17:20:23 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/06/11 17:20:23 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/11 17:20:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/11 17:20:23 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://d86e382532b9:4040
22/06/11 17:20:23 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar at spark://d86e382532b9:39727/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar at spark://d86e382532b9:39727/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar at spark://d86e382532b9:39727/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://d86e382532b9:39727/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://d86e382532b9:39727/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar at spark://d86e382532b9:39727/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://d86e382532b9:39727/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar at spark://d86e382532b9:39727/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://d86e382532b9:39727/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:20:23 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:20:23 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:20:23 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:20:23 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:20:23 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar at file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:20:23 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:20:23 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar at file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:20:23 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:20:23 INFO Executor: Starting executor ID driver on host d86e382532b9
22/06/11 17:20:23 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:20:23 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:20:23 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:20:23 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:20:23 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:20:23 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:20:23 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:20:23 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:20:23 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:20:23 INFO Executor: Fetching spark://d86e382532b9:39727/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO TransportClientFactory: Successfully created connection to d86e382532b9/172.22.0.4:39727 after 15 ms (0 ms spent in bootstraps)
22/06/11 17:20:23 INFO Utils: Fetching spark://d86e382532b9:39727/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp1549982543471284567.tmp
22/06/11 17:20:23 INFO Utils: /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp1549982543471284567.tmp has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:20:23 INFO Executor: Adding file:/tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.lz4_lz4-java-1.7.1.jar to class loader
22/06/11 17:20:23 INFO Executor: Fetching spark://d86e382532b9:39727/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Fetching spark://d86e382532b9:39727/jars/com.github.luben_zstd-jni-1.4.4-3.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp2671813233065762949.tmp
22/06/11 17:20:23 INFO Utils: /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp2671813233065762949.tmp has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:20:23 INFO Executor: Adding file:/tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/com.github.luben_zstd-jni-1.4.4-3.jar to class loader
22/06/11 17:20:23 INFO Executor: Fetching spark://d86e382532b9:39727/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Fetching spark://d86e382532b9:39727/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp1647991545204522010.tmp
22/06/11 17:20:23 INFO Utils: /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp1647991545204522010.tmp has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:20:23 INFO Executor: Adding file:/tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.spark-project.spark_unused-1.0.0.jar to class loader
22/06/11 17:20:23 INFO Executor: Fetching spark://d86e382532b9:39727/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Fetching spark://d86e382532b9:39727/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp8133094710723300328.tmp
22/06/11 17:20:23 INFO Utils: /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp8133094710723300328.tmp has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:20:23 INFO Executor: Adding file:/tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to class loader
22/06/11 17:20:23 INFO Executor: Fetching spark://d86e382532b9:39727/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Fetching spark://d86e382532b9:39727/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp5212848355185956505.tmp
22/06/11 17:20:23 INFO Utils: /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp5212848355185956505.tmp has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:20:23 INFO Executor: Adding file:/tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.slf4j_slf4j-api-1.7.30.jar to class loader
22/06/11 17:20:23 INFO Executor: Fetching spark://d86e382532b9:39727/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Fetching spark://d86e382532b9:39727/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp8689777142745526317.tmp
22/06/11 17:20:23 INFO Utils: /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp8689777142745526317.tmp has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:20:23 INFO Executor: Adding file:/tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to class loader
22/06/11 17:20:23 INFO Executor: Fetching spark://d86e382532b9:39727/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Fetching spark://d86e382532b9:39727/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp7574116109627681924.tmp
22/06/11 17:20:23 INFO Utils: /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp7574116109627681924.tmp has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:20:23 INFO Executor: Adding file:/tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.xerial.snappy_snappy-java-1.1.7.5.jar to class loader
22/06/11 17:20:23 INFO Executor: Fetching spark://d86e382532b9:39727/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Fetching spark://d86e382532b9:39727/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp1253597357842065435.tmp
22/06/11 17:20:23 INFO Utils: /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp1253597357842065435.tmp has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:20:23 INFO Executor: Adding file:/tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.apache.commons_commons-pool2-2.6.2.jar to class loader
22/06/11 17:20:23 INFO Executor: Fetching spark://d86e382532b9:39727/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654968022925
22/06/11 17:20:23 INFO Utils: Fetching spark://d86e382532b9:39727/jars/org.apache.kafka_kafka-clients-2.4.1.jar to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp4448072947580476766.tmp
22/06/11 17:20:23 INFO Utils: /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/fetchFileTemp4448072947580476766.tmp has been previously copied to /tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:20:23 INFO Executor: Adding file:/tmp/spark-db4b1289-2264-457c-ad7e-008d600a68d5/userFiles-c6e1bbb2-46fa-42e6-8759-7482d0df5f4f/org.apache.kafka_kafka-clients-2.4.1.jar to class loader
22/06/11 17:20:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46729.
22/06/11 17:20:23 INFO NettyBlockTransferService: Server created on d86e382532b9:46729
22/06/11 17:20:23 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/11 17:20:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d86e382532b9, 46729, None)
22/06/11 17:20:23 INFO BlockManagerMasterEndpoint: Registering block manager d86e382532b9:46729 with 366.3 MiB RAM, BlockManagerId(driver, d86e382532b9, 46729, None)
22/06/11 17:20:23 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d86e382532b9, 46729, None)
22/06/11 17:20:23 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d86e382532b9, 46729, None)
22/06/11 17:20:24 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/06/11 17:20:24 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
Traceback (most recent call last):
  File "/home/workspace/sparkpykafkajoin.py", line 173, in <module>
    stediRawStreamingDF\
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 2478, in withColumn
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: cannot resolve 'from_json(value)' due to data type mismatch: argument 1 requires string type, however, 'value' is of binary type.;
'Project [key#77, from_json(StructField(customer,StringType,true), StructField(score,StringType,true), StructField(riskDate,StringType,true), value#78, Some(Etc/UTC)) AS value#91, topic#79, partition#80, offset#81L, timestamp#82, timestampType#83]
+- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@556686d1, kafka, org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@9501b51, [startingOffsets=earliest, kafka.bootstrap.servers=localhost:9092, subscribe=stedi-events], [key#77, value#78, topic#79, partition#80, offset#81L, timestamp#82, timestampType#83], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@4e884070,kafka,List(),None,List(),None,Map(kafka.bootstrap.servers -> localhost:9092, subscribe -> stedi-events, startingOffsets -> earliest),None), kafka, [key#70, value#71, topic#72, partition#73, offset#74L, timestamp#75, timestampType#76]

\:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-4983075a-265c-4e22-80ac-ceb8c6132c7a;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central
	found org.apache.kafka#kafka-clients;2.4.1 in central
	found com.github.luben#zstd-jni;1.4.4-3 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.7.5 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 364ms :: artifacts dl 42ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.4-3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.7.5 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-4983075a-265c-4e22-80ac-ceb8c6132c7a
	confs: [default]
	0 artifacts copied, 9 already retrieved (0kB/11ms)
22/06/11 17:30:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/11 17:30:23 INFO SparkContext: Running Spark version 3.2.1
22/06/11 17:30:23 INFO ResourceUtils: ==============================================================
22/06/11 17:30:23 INFO ResourceUtils: No custom resources configured for spark.driver.
22/06/11 17:30:23 INFO ResourceUtils: ==============================================================
22/06/11 17:30:23 INFO SparkContext: Submitted application: Evaluate-Human-Balance
22/06/11 17:30:23 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/06/11 17:30:23 INFO ResourceProfile: Limiting resource is cpu
22/06/11 17:30:23 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/06/11 17:30:23 INFO SecurityManager: Changing view acls to: spark
22/06/11 17:30:23 INFO SecurityManager: Changing modify acls to: spark
22/06/11 17:30:23 INFO SecurityManager: Changing view acls groups to: 
22/06/11 17:30:23 INFO SecurityManager: Changing modify acls groups to: 
22/06/11 17:30:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
22/06/11 17:30:23 INFO Utils: Successfully started service 'sparkDriver' on port 33477.
22/06/11 17:30:23 INFO SparkEnv: Registering MapOutputTracker
22/06/11 17:30:23 INFO SparkEnv: Registering BlockManagerMaster
22/06/11 17:30:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/11 17:30:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/11 17:30:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/06/11 17:30:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-248b221c-4bd3-4dd5-b9ec-8433d52ed125
22/06/11 17:30:23 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/06/11 17:30:23 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/11 17:30:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/11 17:30:24 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://d86e382532b9:4040
22/06/11 17:30:24 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar at spark://d86e382532b9:33477/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar at spark://d86e382532b9:33477/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar at spark://d86e382532b9:33477/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://d86e382532b9:33477/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://d86e382532b9:33477/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar at spark://d86e382532b9:33477/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://d86e382532b9:33477/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar at spark://d86e382532b9:33477/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://d86e382532b9:33477/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:30:24 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:30:24 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:30:24 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:30:24 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:30:24 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar at file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:30:24 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:30:24 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar at file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:30:24 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:30:24 INFO Executor: Starting executor ID driver on host d86e382532b9
22/06/11 17:30:24 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:30:24 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:30:24 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:30:24 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:30:24 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:30:24 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:30:24 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:30:24 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:30:24 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:30:24 INFO Executor: Fetching spark://d86e382532b9:33477/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO TransportClientFactory: Successfully created connection to d86e382532b9/172.22.0.4:33477 after 15 ms (0 ms spent in bootstraps)
22/06/11 17:30:24 INFO Utils: Fetching spark://d86e382532b9:33477/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp4548031911914122348.tmp
22/06/11 17:30:24 INFO Utils: /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp4548031911914122348.tmp has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:30:24 INFO Executor: Adding file:/tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.slf4j_slf4j-api-1.7.30.jar to class loader
22/06/11 17:30:24 INFO Executor: Fetching spark://d86e382532b9:33477/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Fetching spark://d86e382532b9:33477/jars/com.github.luben_zstd-jni-1.4.4-3.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp458685762154192064.tmp
22/06/11 17:30:24 INFO Utils: /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp458685762154192064.tmp has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:30:24 INFO Executor: Adding file:/tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/com.github.luben_zstd-jni-1.4.4-3.jar to class loader
22/06/11 17:30:24 INFO Executor: Fetching spark://d86e382532b9:33477/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Fetching spark://d86e382532b9:33477/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp6146613869692423527.tmp
22/06/11 17:30:24 INFO Utils: /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp6146613869692423527.tmp has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:30:24 INFO Executor: Adding file:/tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to class loader
22/06/11 17:30:24 INFO Executor: Fetching spark://d86e382532b9:33477/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Fetching spark://d86e382532b9:33477/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp5828933110413417610.tmp
22/06/11 17:30:24 INFO Utils: /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp5828933110413417610.tmp has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:30:24 INFO Executor: Adding file:/tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to class loader
22/06/11 17:30:24 INFO Executor: Fetching spark://d86e382532b9:33477/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Fetching spark://d86e382532b9:33477/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp1131301212287488227.tmp
22/06/11 17:30:24 INFO Utils: /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp1131301212287488227.tmp has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:30:24 INFO Executor: Adding file:/tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.xerial.snappy_snappy-java-1.1.7.5.jar to class loader
22/06/11 17:30:24 INFO Executor: Fetching spark://d86e382532b9:33477/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Fetching spark://d86e382532b9:33477/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp6507582493430924488.tmp
22/06/11 17:30:24 INFO Utils: /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp6507582493430924488.tmp has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:30:24 INFO Executor: Adding file:/tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.lz4_lz4-java-1.7.1.jar to class loader
22/06/11 17:30:24 INFO Executor: Fetching spark://d86e382532b9:33477/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Fetching spark://d86e382532b9:33477/jars/org.apache.kafka_kafka-clients-2.4.1.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp7285584837902817295.tmp
22/06/11 17:30:24 INFO Utils: /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp7285584837902817295.tmp has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:30:24 INFO Executor: Adding file:/tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.apache.kafka_kafka-clients-2.4.1.jar to class loader
22/06/11 17:30:24 INFO Executor: Fetching spark://d86e382532b9:33477/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Fetching spark://d86e382532b9:33477/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp5525393701829535815.tmp
22/06/11 17:30:24 INFO Utils: /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp5525393701829535815.tmp has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:30:24 INFO Executor: Adding file:/tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.apache.commons_commons-pool2-2.6.2.jar to class loader
22/06/11 17:30:24 INFO Executor: Fetching spark://d86e382532b9:33477/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654968623492
22/06/11 17:30:24 INFO Utils: Fetching spark://d86e382532b9:33477/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp3654567304078179774.tmp
22/06/11 17:30:24 INFO Utils: /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/fetchFileTemp3654567304078179774.tmp has been previously copied to /tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:30:24 INFO Executor: Adding file:/tmp/spark-120204bd-fd63-4d90-8559-2d5f3933f8b2/userFiles-111f9e1e-8696-4a70-b628-692c6de4c9f9/org.spark-project.spark_unused-1.0.0.jar to class loader
22/06/11 17:30:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45695.
22/06/11 17:30:24 INFO NettyBlockTransferService: Server created on d86e382532b9:45695
22/06/11 17:30:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/11 17:30:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d86e382532b9, 45695, None)
22/06/11 17:30:24 INFO BlockManagerMasterEndpoint: Registering block manager d86e382532b9:45695 with 366.3 MiB RAM, BlockManagerId(driver, d86e382532b9, 45695, None)
22/06/11 17:30:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d86e382532b9, 45695, None)
22/06/11 17:30:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d86e382532b9, 45695, None)
22/06/11 17:30:24 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/06/11 17:30:24 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
Traceback (most recent call last):
  File "/home/workspace/sparkpykafkajoin.py", line 173, in <module>
    stediRawStreamingDF\
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 2478, in withColumn
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: cannot resolve 'from_json(value)' due to data type mismatch: argument 1 requires string type, however, 'value' is of binary type.;
'Project [key#77, from_json(StructField(customer,StringType,true), StructField(score,StringType,true), StructField(riskDate,StringType,true), value#78, Some(Etc/UTC)) AS value#91, topic#79, partition#80, offset#81L, timestamp#82, timestampType#83]
+- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@782ee5d0, kafka, org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@7a485108, [startingOffsets=earliest, kafka.bootstrap.servers=localhost:9092, subscribe=stedi-events], [key#77, value#78, topic#79, partition#80, offset#81L, timestamp#82, timestampType#83], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@a966cdb,kafka,List(),None,List(),None,Map(kafka.bootstrap.servers -> localhost:9092, subscribe -> stedi-events, startingOffsets -> earliest),None), kafka, [key#70, value#71, topic#72, partition#73, offset#74L, timestamp#75, timestampType#76]

:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-be6dcb2c-65a9-4e33-9d61-f70588439698;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central
	found org.apache.kafka#kafka-clients;2.4.1 in central
	found com.github.luben#zstd-jni;1.4.4-3 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.7.5 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 343ms :: artifacts dl 42ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.4-3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.7.5 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-be6dcb2c-65a9-4e33-9d61-f70588439698
	confs: [default]
	0 artifacts copied, 9 already retrieved (0kB/11ms)
22/06/11 17:33:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/11 17:33:43 INFO SparkContext: Running Spark version 3.2.1
22/06/11 17:33:43 INFO ResourceUtils: ==============================================================
22/06/11 17:33:43 INFO ResourceUtils: No custom resources configured for spark.driver.
22/06/11 17:33:43 INFO ResourceUtils: ==============================================================
22/06/11 17:33:43 INFO SparkContext: Submitted application: Evaluate-Human-Balance
22/06/11 17:33:43 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/06/11 17:33:43 INFO ResourceProfile: Limiting resource is cpu
22/06/11 17:33:43 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/06/11 17:33:43 INFO SecurityManager: Changing view acls to: spark
22/06/11 17:33:43 INFO SecurityManager: Changing modify acls to: spark
22/06/11 17:33:43 INFO SecurityManager: Changing view acls groups to: 
22/06/11 17:33:43 INFO SecurityManager: Changing modify acls groups to: 
22/06/11 17:33:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
22/06/11 17:33:43 INFO Utils: Successfully started service 'sparkDriver' on port 43141.
22/06/11 17:33:43 INFO SparkEnv: Registering MapOutputTracker
22/06/11 17:33:43 INFO SparkEnv: Registering BlockManagerMaster
22/06/11 17:33:43 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/11 17:33:43 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/11 17:33:43 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/06/11 17:33:43 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7d27f089-8fae-4d8e-b1c9-322e105a1818
22/06/11 17:33:43 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/06/11 17:33:43 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/11 17:33:43 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/11 17:33:43 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://d86e382532b9:4040
22/06/11 17:33:43 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar at spark://d86e382532b9:43141/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar at spark://d86e382532b9:43141/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar at spark://d86e382532b9:43141/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://d86e382532b9:43141/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://d86e382532b9:43141/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar at spark://d86e382532b9:43141/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://d86e382532b9:43141/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar at spark://d86e382532b9:43141/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://d86e382532b9:43141/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:33:43 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:33:43 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:33:43 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:33:43 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:33:43 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar at file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:33:43 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:33:43 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar at file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:33:43 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:33:43 INFO Executor: Starting executor ID driver on host d86e382532b9
22/06/11 17:33:43 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:33:43 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:33:43 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:33:43 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:33:43 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:33:43 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:33:43 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:33:43 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:33:43 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:33:43 INFO Executor: Fetching spark://d86e382532b9:43141/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO TransportClientFactory: Successfully created connection to d86e382532b9/172.22.0.4:43141 after 15 ms (0 ms spent in bootstraps)
22/06/11 17:33:43 INFO Utils: Fetching spark://d86e382532b9:43141/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp6069457385762017657.tmp
22/06/11 17:33:43 INFO Utils: /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp6069457385762017657.tmp has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:33:43 INFO Executor: Adding file:/tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to class loader
22/06/11 17:33:43 INFO Executor: Fetching spark://d86e382532b9:43141/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Fetching spark://d86e382532b9:43141/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp9004787434967765566.tmp
22/06/11 17:33:43 INFO Utils: /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp9004787434967765566.tmp has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:33:43 INFO Executor: Adding file:/tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.spark-project.spark_unused-1.0.0.jar to class loader
22/06/11 17:33:43 INFO Executor: Fetching spark://d86e382532b9:43141/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Fetching spark://d86e382532b9:43141/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp8423709789613369350.tmp
22/06/11 17:33:43 INFO Utils: /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp8423709789613369350.tmp has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:33:43 INFO Executor: Adding file:/tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.slf4j_slf4j-api-1.7.30.jar to class loader
22/06/11 17:33:43 INFO Executor: Fetching spark://d86e382532b9:43141/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Fetching spark://d86e382532b9:43141/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp3628661083094701692.tmp
22/06/11 17:33:43 INFO Utils: /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp3628661083094701692.tmp has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:33:43 INFO Executor: Adding file:/tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.lz4_lz4-java-1.7.1.jar to class loader
22/06/11 17:33:43 INFO Executor: Fetching spark://d86e382532b9:43141/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Fetching spark://d86e382532b9:43141/jars/com.github.luben_zstd-jni-1.4.4-3.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp5131820999023269054.tmp
22/06/11 17:33:43 INFO Utils: /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp5131820999023269054.tmp has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:33:43 INFO Executor: Adding file:/tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/com.github.luben_zstd-jni-1.4.4-3.jar to class loader
22/06/11 17:33:43 INFO Executor: Fetching spark://d86e382532b9:43141/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Fetching spark://d86e382532b9:43141/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp3961005081141430334.tmp
22/06/11 17:33:43 INFO Utils: /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp3961005081141430334.tmp has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:33:43 INFO Executor: Adding file:/tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.apache.commons_commons-pool2-2.6.2.jar to class loader
22/06/11 17:33:43 INFO Executor: Fetching spark://d86e382532b9:43141/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Fetching spark://d86e382532b9:43141/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp635161167909792716.tmp
22/06/11 17:33:43 INFO Utils: /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp635161167909792716.tmp has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:33:43 INFO Executor: Adding file:/tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.xerial.snappy_snappy-java-1.1.7.5.jar to class loader
22/06/11 17:33:43 INFO Executor: Fetching spark://d86e382532b9:43141/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Fetching spark://d86e382532b9:43141/jars/org.apache.kafka_kafka-clients-2.4.1.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp5258179473003812722.tmp
22/06/11 17:33:43 INFO Utils: /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp5258179473003812722.tmp has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:33:43 INFO Executor: Adding file:/tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.apache.kafka_kafka-clients-2.4.1.jar to class loader
22/06/11 17:33:43 INFO Executor: Fetching spark://d86e382532b9:43141/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968823206
22/06/11 17:33:43 INFO Utils: Fetching spark://d86e382532b9:43141/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp2520366418601943556.tmp
22/06/11 17:33:43 INFO Utils: /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/fetchFileTemp2520366418601943556.tmp has been previously copied to /tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:33:43 INFO Executor: Adding file:/tmp/spark-f7b2b3a6-97e6-4e1e-b502-7c85e5cf8760/userFiles-a352f22e-1436-4b32-b403-90d2ae8d82dd/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to class loader
22/06/11 17:33:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39083.
22/06/11 17:33:43 INFO NettyBlockTransferService: Server created on d86e382532b9:39083
22/06/11 17:33:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/11 17:33:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d86e382532b9, 39083, None)
22/06/11 17:33:43 INFO BlockManagerMasterEndpoint: Registering block manager d86e382532b9:39083 with 366.3 MiB RAM, BlockManagerId(driver, d86e382532b9, 39083, None)
22/06/11 17:33:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d86e382532b9, 39083, None)
22/06/11 17:33:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d86e382532b9, 39083, None)
22/06/11 17:33:44 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/06/11 17:33:44 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
Traceback (most recent call last):
  File "/home/workspace/sparkpykafkajoin.py", line 173, in <module>
    stediRawStreamingDF\
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 2478, in withColumn
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: cannot resolve 'from_json(value)' due to data type mismatch: argument 1 requires string type, however, 'value' is of binary type.;
'Project [key#77, from_json(StructField(customer,StringType,true), StructField(score,StringType,true), StructField(riskDate,StringType,true), value#78, Some(Etc/UTC)) AS value#91, topic#79, partition#80, offset#81L, timestamp#82, timestampType#83]
+- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@782ee5d0, kafka, org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@7a485108, [startingOffsets=earliest, kafka.bootstrap.servers=localhost:9092, subscribe=stedi-events], [key#77, value#78, topic#79, partition#80, offset#81L, timestamp#82, timestampType#83], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@a966cdb,kafka,List(),None,List(),None,Map(kafka.bootstrap.servers -> localhost:9092, subscribe -> stedi-events, startingOffsets -> earliest),None), kafka, [key#70, value#71, topic#72, partition#73, offset#74L, timestamp#75, timestampType#76]

:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-4d51e445-ba39-41fd-bc07-47cec6defc6f;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central
	found org.apache.kafka#kafka-clients;2.4.1 in central
	found com.github.luben#zstd-jni;1.4.4-3 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.7.5 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 384ms :: artifacts dl 46ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.4-3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.7.5 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-4d51e445-ba39-41fd-bc07-47cec6defc6f
	confs: [default]
	0 artifacts copied, 9 already retrieved (0kB/13ms)
22/06/11 17:36:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/11 17:36:11 INFO SparkContext: Running Spark version 3.2.1
22/06/11 17:36:11 INFO ResourceUtils: ==============================================================
22/06/11 17:36:11 INFO ResourceUtils: No custom resources configured for spark.driver.
22/06/11 17:36:11 INFO ResourceUtils: ==============================================================
22/06/11 17:36:11 INFO SparkContext: Submitted application: Evaluate-Human-Balance
22/06/11 17:36:11 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/06/11 17:36:11 INFO ResourceProfile: Limiting resource is cpu
22/06/11 17:36:11 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/06/11 17:36:11 INFO SecurityManager: Changing view acls to: spark
22/06/11 17:36:11 INFO SecurityManager: Changing modify acls to: spark
22/06/11 17:36:11 INFO SecurityManager: Changing view acls groups to: 
22/06/11 17:36:11 INFO SecurityManager: Changing modify acls groups to: 
22/06/11 17:36:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
22/06/11 17:36:12 INFO Utils: Successfully started service 'sparkDriver' on port 41869.
22/06/11 17:36:12 INFO SparkEnv: Registering MapOutputTracker
22/06/11 17:36:12 INFO SparkEnv: Registering BlockManagerMaster
22/06/11 17:36:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/11 17:36:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/11 17:36:12 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/06/11 17:36:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0261acdf-25d5-4b9c-a2e5-b9718bc06f97
22/06/11 17:36:12 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/06/11 17:36:12 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/11 17:36:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/11 17:36:12 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://d86e382532b9:4040
22/06/11 17:36:12 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar at spark://d86e382532b9:41869/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar at spark://d86e382532b9:41869/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar at spark://d86e382532b9:41869/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://d86e382532b9:41869/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://d86e382532b9:41869/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar at spark://d86e382532b9:41869/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://d86e382532b9:41869/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar at spark://d86e382532b9:41869/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://d86e382532b9:41869/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:36:12 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:36:12 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:36:12 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:36:12 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:36:12 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar at file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:36:12 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:36:12 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar at file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:36:12 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:36:12 INFO Executor: Starting executor ID driver on host d86e382532b9
22/06/11 17:36:12 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:36:12 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:36:12 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:36:12 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:36:12 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:36:12 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:36:12 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:36:12 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:36:12 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:36:12 INFO Executor: Fetching spark://d86e382532b9:41869/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO TransportClientFactory: Successfully created connection to d86e382532b9/172.22.0.4:41869 after 16 ms (0 ms spent in bootstraps)
22/06/11 17:36:12 INFO Utils: Fetching spark://d86e382532b9:41869/jars/org.apache.kafka_kafka-clients-2.4.1.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp4304615640107193285.tmp
22/06/11 17:36:12 INFO Utils: /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp4304615640107193285.tmp has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:36:12 INFO Executor: Adding file:/tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.apache.kafka_kafka-clients-2.4.1.jar to class loader
22/06/11 17:36:12 INFO Executor: Fetching spark://d86e382532b9:41869/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Fetching spark://d86e382532b9:41869/jars/com.github.luben_zstd-jni-1.4.4-3.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp8005939886890337590.tmp
22/06/11 17:36:12 INFO Utils: /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp8005939886890337590.tmp has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:36:12 INFO Executor: Adding file:/tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/com.github.luben_zstd-jni-1.4.4-3.jar to class loader
22/06/11 17:36:12 INFO Executor: Fetching spark://d86e382532b9:41869/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Fetching spark://d86e382532b9:41869/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp6651918278131411988.tmp
22/06/11 17:36:12 INFO Utils: /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp6651918278131411988.tmp has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:36:12 INFO Executor: Adding file:/tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.spark-project.spark_unused-1.0.0.jar to class loader
22/06/11 17:36:12 INFO Executor: Fetching spark://d86e382532b9:41869/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Fetching spark://d86e382532b9:41869/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp6378406712131423327.tmp
22/06/11 17:36:12 INFO Utils: /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp6378406712131423327.tmp has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:36:12 INFO Executor: Adding file:/tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.lz4_lz4-java-1.7.1.jar to class loader
22/06/11 17:36:12 INFO Executor: Fetching spark://d86e382532b9:41869/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Fetching spark://d86e382532b9:41869/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp3522567257643420184.tmp
22/06/11 17:36:12 INFO Utils: /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp3522567257643420184.tmp has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:36:12 INFO Executor: Adding file:/tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.slf4j_slf4j-api-1.7.30.jar to class loader
22/06/11 17:36:12 INFO Executor: Fetching spark://d86e382532b9:41869/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Fetching spark://d86e382532b9:41869/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp250250543046139066.tmp
22/06/11 17:36:12 INFO Utils: /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp250250543046139066.tmp has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:36:12 INFO Executor: Adding file:/tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.xerial.snappy_snappy-java-1.1.7.5.jar to class loader
22/06/11 17:36:12 INFO Executor: Fetching spark://d86e382532b9:41869/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Fetching spark://d86e382532b9:41869/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp852044438344053887.tmp
22/06/11 17:36:12 INFO Utils: /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp852044438344053887.tmp has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:36:12 INFO Executor: Adding file:/tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to class loader
22/06/11 17:36:12 INFO Executor: Fetching spark://d86e382532b9:41869/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Fetching spark://d86e382532b9:41869/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp3273989771331512835.tmp
22/06/11 17:36:12 INFO Utils: /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp3273989771331512835.tmp has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:36:12 INFO Executor: Adding file:/tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to class loader
22/06/11 17:36:12 INFO Executor: Fetching spark://d86e382532b9:41869/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654968971823
22/06/11 17:36:12 INFO Utils: Fetching spark://d86e382532b9:41869/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp2434796074076424077.tmp
22/06/11 17:36:12 INFO Utils: /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/fetchFileTemp2434796074076424077.tmp has been previously copied to /tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:36:12 INFO Executor: Adding file:/tmp/spark-4742c106-797b-4287-859e-59a65bffdc54/userFiles-0986be23-5a1a-4c2f-a588-6c52e0e41f36/org.apache.commons_commons-pool2-2.6.2.jar to class loader
22/06/11 17:36:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46493.
22/06/11 17:36:12 INFO NettyBlockTransferService: Server created on d86e382532b9:46493
22/06/11 17:36:12 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/11 17:36:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d86e382532b9, 46493, None)
22/06/11 17:36:12 INFO BlockManagerMasterEndpoint: Registering block manager d86e382532b9:46493 with 366.3 MiB RAM, BlockManagerId(driver, d86e382532b9, 46493, None)
22/06/11 17:36:12 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d86e382532b9, 46493, None)
22/06/11 17:36:12 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d86e382532b9, 46493, None)
22/06/11 17:36:12 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/06/11 17:36:12 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
22/06/11 17:36:15 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
22/06/11 17:36:15 ERROR MicroBatchExecution: Query [id = 017363b8-5645-4409-b186-f7817067c1f5, runId = f92b32b5-78e6-4e15-8609-5493ddef66dd] terminated with error
java.lang.NoClassDefFoundError: org/apache/spark/sql/internal/connector/SupportsStreamingUpdate
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:756)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:473)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable.newWriteBuilder(KafkaSourceProvider.scala:397)
	at org.apache.spark.sql.execution.streaming.StreamExecution.createStreamingWrite(StreamExecution.scala:590)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.logicalPlan$lzycompute(MicroBatchExecution.scala:140)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.logicalPlan(MicroBatchExecution.scala:59)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:286)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:209)
Caused by: java.lang.ClassNotFoundException: org.apache.spark.sql.internal.connector.SupportsStreamingUpdate
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more
Exception in thread "stream execution thread for [id = 017363b8-5645-4409-b186-f7817067c1f5, runId = f92b32b5-78e6-4e15-8609-5493ddef66dd]" java.lang.NoClassDefFoundError: org/apache/spark/sql/internal/connector/SupportsStreamingUpdate
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:756)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:473)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable.newWriteBuilder(KafkaSourceProvider.scala:397)
	at org.apache.spark.sql.execution.streaming.StreamExecution.createStreamingWrite(StreamExecution.scala:590)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.logicalPlan$lzycompute(MicroBatchExecution.scala:140)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.logicalPlan(MicroBatchExecution.scala:59)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:286)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:209)
Caused by: java.lang.ClassNotFoundException: org.apache.spark.sql.internal.connector.SupportsStreamingUpdate
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more
Traceback (most recent call last):
  File "/home/workspace/sparkpykafkajoin.py", line 200, in <module>
    customerRiskStreamingDF.selectExpr("CAST(customer AS STRING) AS key", "to_json(struct(*)) AS value")\
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming.py", line 101, in awaitTermination
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.StreamingQueryException: org/apache/spark/sql/internal/connector/SupportsStreamingUpdate
=== Streaming Query ===
Identifier: [id = 017363b8-5645-4409-b186-f7817067c1f5, runId = f92b32b5-78e6-4e15-8609-5493ddef66dd]
Current Committed Offsets: {}
Current Available Offsets: {}

Current State: INITIALIZING
Thread State: RUNNABLE
:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-c21456ad-5b6f-4887-802b-fbb605fff874;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central
	found org.apache.kafka#kafka-clients;2.4.1 in central
	found com.github.luben#zstd-jni;1.4.4-3 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.7.5 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 352ms :: artifacts dl 41ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.4-3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.7.5 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-c21456ad-5b6f-4887-802b-fbb605fff874
	confs: [default]
	0 artifacts copied, 9 already retrieved (0kB/11ms)
22/06/11 17:37:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/11 17:37:17 INFO SparkContext: Running Spark version 3.2.1
22/06/11 17:37:17 INFO ResourceUtils: ==============================================================
22/06/11 17:37:17 INFO ResourceUtils: No custom resources configured for spark.driver.
22/06/11 17:37:17 INFO ResourceUtils: ==============================================================
22/06/11 17:37:17 INFO SparkContext: Submitted application: Evaluate-Human-Balance
22/06/11 17:37:17 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/06/11 17:37:17 INFO ResourceProfile: Limiting resource is cpu
22/06/11 17:37:17 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/06/11 17:37:17 INFO SecurityManager: Changing view acls to: spark
22/06/11 17:37:17 INFO SecurityManager: Changing modify acls to: spark
22/06/11 17:37:17 INFO SecurityManager: Changing view acls groups to: 
22/06/11 17:37:17 INFO SecurityManager: Changing modify acls groups to: 
22/06/11 17:37:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
22/06/11 17:37:17 INFO Utils: Successfully started service 'sparkDriver' on port 37297.
22/06/11 17:37:17 INFO SparkEnv: Registering MapOutputTracker
22/06/11 17:37:17 INFO SparkEnv: Registering BlockManagerMaster
22/06/11 17:37:17 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/11 17:37:17 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/11 17:37:17 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/06/11 17:37:17 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b922be25-da19-4fcf-940d-4a0f5e63a836
22/06/11 17:37:17 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/06/11 17:37:17 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/11 17:37:17 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/11 17:37:17 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://d86e382532b9:4040
22/06/11 17:37:17 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar at spark://d86e382532b9:37297/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar at spark://d86e382532b9:37297/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar at spark://d86e382532b9:37297/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://d86e382532b9:37297/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://d86e382532b9:37297/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar at spark://d86e382532b9:37297/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://d86e382532b9:37297/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar at spark://d86e382532b9:37297/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://d86e382532b9:37297/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:37:17 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:37:17 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:37:17 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:37:17 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:37:17 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar at file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:37:17 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:37:17 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar at file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:37:17 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:37:17 INFO Executor: Starting executor ID driver on host d86e382532b9
22/06/11 17:37:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:37:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:37:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:37:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:37:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:37:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:37:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:37:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:37:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:37:17 INFO Executor: Fetching spark://d86e382532b9:37297/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO TransportClientFactory: Successfully created connection to d86e382532b9/172.22.0.4:37297 after 16 ms (0 ms spent in bootstraps)
22/06/11 17:37:17 INFO Utils: Fetching spark://d86e382532b9:37297/jars/org.apache.kafka_kafka-clients-2.4.1.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp804742826847112718.tmp
22/06/11 17:37:17 INFO Utils: /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp804742826847112718.tmp has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:37:17 INFO Executor: Adding file:/tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.apache.kafka_kafka-clients-2.4.1.jar to class loader
22/06/11 17:37:17 INFO Executor: Fetching spark://d86e382532b9:37297/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Fetching spark://d86e382532b9:37297/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp7144001975764572904.tmp
22/06/11 17:37:17 INFO Utils: /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp7144001975764572904.tmp has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:37:17 INFO Executor: Adding file:/tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.xerial.snappy_snappy-java-1.1.7.5.jar to class loader
22/06/11 17:37:17 INFO Executor: Fetching spark://d86e382532b9:37297/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Fetching spark://d86e382532b9:37297/jars/com.github.luben_zstd-jni-1.4.4-3.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp3415367267382141314.tmp
22/06/11 17:37:17 INFO Utils: /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp3415367267382141314.tmp has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:37:17 INFO Executor: Adding file:/tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/com.github.luben_zstd-jni-1.4.4-3.jar to class loader
22/06/11 17:37:17 INFO Executor: Fetching spark://d86e382532b9:37297/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Fetching spark://d86e382532b9:37297/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp4918924822372936507.tmp
22/06/11 17:37:17 INFO Utils: /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp4918924822372936507.tmp has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:37:17 INFO Executor: Adding file:/tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.spark-project.spark_unused-1.0.0.jar to class loader
22/06/11 17:37:17 INFO Executor: Fetching spark://d86e382532b9:37297/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Fetching spark://d86e382532b9:37297/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp6104337103959379125.tmp
22/06/11 17:37:17 INFO Utils: /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp6104337103959379125.tmp has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:37:17 INFO Executor: Adding file:/tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to class loader
22/06/11 17:37:17 INFO Executor: Fetching spark://d86e382532b9:37297/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Fetching spark://d86e382532b9:37297/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp4319495115650469181.tmp
22/06/11 17:37:17 INFO Utils: /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp4319495115650469181.tmp has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:37:17 INFO Executor: Adding file:/tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.lz4_lz4-java-1.7.1.jar to class loader
22/06/11 17:37:17 INFO Executor: Fetching spark://d86e382532b9:37297/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Fetching spark://d86e382532b9:37297/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp5545036993445338501.tmp
22/06/11 17:37:17 INFO Utils: /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp5545036993445338501.tmp has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:37:17 INFO Executor: Adding file:/tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to class loader
22/06/11 17:37:17 INFO Executor: Fetching spark://d86e382532b9:37297/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Fetching spark://d86e382532b9:37297/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp2114617562822513386.tmp
22/06/11 17:37:17 INFO Utils: /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp2114617562822513386.tmp has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:37:17 INFO Executor: Adding file:/tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.slf4j_slf4j-api-1.7.30.jar to class loader
22/06/11 17:37:17 INFO Executor: Fetching spark://d86e382532b9:37297/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654969037125
22/06/11 17:37:17 INFO Utils: Fetching spark://d86e382532b9:37297/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp377786177534518412.tmp
22/06/11 17:37:17 INFO Utils: /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/fetchFileTemp377786177534518412.tmp has been previously copied to /tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:37:17 INFO Executor: Adding file:/tmp/spark-c3750a6e-24fe-4259-9a96-bcfe14554d7c/userFiles-68bb9859-9b04-4879-9023-50f2e94fbb31/org.apache.commons_commons-pool2-2.6.2.jar to class loader
22/06/11 17:37:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40855.
22/06/11 17:37:17 INFO NettyBlockTransferService: Server created on d86e382532b9:40855
22/06/11 17:37:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/11 17:37:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d86e382532b9, 40855, None)
22/06/11 17:37:17 INFO BlockManagerMasterEndpoint: Registering block manager d86e382532b9:40855 with 366.3 MiB RAM, BlockManagerId(driver, d86e382532b9, 40855, None)
22/06/11 17:37:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d86e382532b9, 40855, None)
22/06/11 17:37:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d86e382532b9, 40855, None)
22/06/11 17:37:18 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/06/11 17:37:18 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
22/06/11 17:37:20 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
22/06/11 17:37:20 ERROR MicroBatchExecution: Query [id = 017363b8-5645-4409-b186-f7817067c1f5, runId = 3485ac9f-2f02-4398-802a-36bb857a8de3] terminated with error
java.lang.NoClassDefFoundError: org/apache/spark/sql/internal/connector/SupportsStreamingUpdate
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:756)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:473)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable.newWriteBuilder(KafkaSourceProvider.scala:397)
	at org.apache.spark.sql.execution.streaming.StreamExecution.createStreamingWrite(StreamExecution.scala:590)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.logicalPlan$lzycompute(MicroBatchExecution.scala:140)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.logicalPlan(MicroBatchExecution.scala:59)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:286)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:209)
Caused by: java.lang.ClassNotFoundException: org.apache.spark.sql.internal.connector.SupportsStreamingUpdate
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more
Exception in thread "stream execution thread for [id = 017363b8-5645-4409-b186-f7817067c1f5, runId = 3485ac9f-2f02-4398-802a-36bb857a8de3]" java.lang.NoClassDefFoundError: org/apache/spark/sql/internal/connector/SupportsStreamingUpdate
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:756)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:473)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable.newWriteBuilder(KafkaSourceProvider.scala:397)
	at org.apache.spark.sql.execution.streaming.StreamExecution.createStreamingWrite(StreamExecution.scala:590)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.logicalPlan$lzycompute(MicroBatchExecution.scala:140)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.logicalPlan(MicroBatchExecution.scala:59)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:286)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:209)
Caused by: java.lang.ClassNotFoundException: org.apache.spark.sql.internal.connector.SupportsStreamingUpdate
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more
Traceback (most recent call last):
  File "/home/workspace/sparkpykafkajoin.py", line 200, in <module>
    customerRiskStreamingDF.selectExpr("to_json(struct(*)) AS value")\
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming.py", line 101, in awaitTermination
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.StreamingQueryException: org/apache/spark/sql/internal/connector/SupportsStreamingUpdate
=== Streaming Query ===
Identifier: [id = 017363b8-5645-4409-b186-f7817067c1f5, runId = 3485ac9f-2f02-4398-802a-36bb857a8de3]
Current Committed Offsets: {}
Current Available Offsets: {}

Current State: INITIALIZING
Thread State: RUNNABLE
:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-47ce5635-a1b7-4694-b7d9-343816592466;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central
	found org.apache.kafka#kafka-clients;2.4.1 in central
	found com.github.luben#zstd-jni;1.4.4-3 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.7.5 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 353ms :: artifacts dl 40ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.4-3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.7.5 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-47ce5635-a1b7-4694-b7d9-343816592466
	confs: [default]
	0 artifacts copied, 9 already retrieved (0kB/11ms)
22/06/11 17:43:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/11 17:43:06 INFO SparkContext: Running Spark version 3.2.1
22/06/11 17:43:06 INFO ResourceUtils: ==============================================================
22/06/11 17:43:06 INFO ResourceUtils: No custom resources configured for spark.driver.
22/06/11 17:43:06 INFO ResourceUtils: ==============================================================
22/06/11 17:43:06 INFO SparkContext: Submitted application: Evaluate-Human-Balance
22/06/11 17:43:06 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/06/11 17:43:06 INFO ResourceProfile: Limiting resource is cpu
22/06/11 17:43:06 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/06/11 17:43:06 INFO SecurityManager: Changing view acls to: spark
22/06/11 17:43:06 INFO SecurityManager: Changing modify acls to: spark
22/06/11 17:43:06 INFO SecurityManager: Changing view acls groups to: 
22/06/11 17:43:06 INFO SecurityManager: Changing modify acls groups to: 
22/06/11 17:43:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
22/06/11 17:43:06 INFO Utils: Successfully started service 'sparkDriver' on port 40497.
22/06/11 17:43:06 INFO SparkEnv: Registering MapOutputTracker
22/06/11 17:43:06 INFO SparkEnv: Registering BlockManagerMaster
22/06/11 17:43:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/11 17:43:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/11 17:43:06 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/06/11 17:43:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6b5d9f79-7037-49d1-851b-8c13b01c58d9
22/06/11 17:43:06 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/06/11 17:43:06 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/11 17:43:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/11 17:43:06 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://d86e382532b9:4040
22/06/11 17:43:06 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar at spark://d86e382532b9:40497/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar at spark://d86e382532b9:40497/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar at spark://d86e382532b9:40497/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://d86e382532b9:40497/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://d86e382532b9:40497/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar at spark://d86e382532b9:40497/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://d86e382532b9:40497/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar at spark://d86e382532b9:40497/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://d86e382532b9:40497/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:43:06 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:43:06 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:43:06 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:43:06 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:43:06 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar at file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:43:06 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:43:06 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar at file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:43:06 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:43:06 INFO Executor: Starting executor ID driver on host d86e382532b9
22/06/11 17:43:06 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:43:06 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:43:06 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:43:06 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:43:06 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:43:06 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:43:06 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:43:06 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:43:06 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:43:06 INFO Executor: Fetching spark://d86e382532b9:40497/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO TransportClientFactory: Successfully created connection to d86e382532b9/172.22.0.4:40497 after 15 ms (0 ms spent in bootstraps)
22/06/11 17:43:06 INFO Utils: Fetching spark://d86e382532b9:40497/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp6118740173071625520.tmp
22/06/11 17:43:06 INFO Utils: /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp6118740173071625520.tmp has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:43:06 INFO Executor: Adding file:/tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.lz4_lz4-java-1.7.1.jar to class loader
22/06/11 17:43:06 INFO Executor: Fetching spark://d86e382532b9:40497/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Fetching spark://d86e382532b9:40497/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp7644515315919758185.tmp
22/06/11 17:43:06 INFO Utils: /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp7644515315919758185.tmp has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.xerial.snappy_snappy-java-1.1.7.5.jar
22/06/11 17:43:06 INFO Executor: Adding file:/tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.xerial.snappy_snappy-java-1.1.7.5.jar to class loader
22/06/11 17:43:06 INFO Executor: Fetching spark://d86e382532b9:40497/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Fetching spark://d86e382532b9:40497/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp5812558857047917856.tmp
22/06/11 17:43:06 INFO Utils: /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp5812558857047917856.tmp has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:43:06 INFO Executor: Adding file:/tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to class loader
22/06/11 17:43:06 INFO Executor: Fetching spark://d86e382532b9:40497/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Fetching spark://d86e382532b9:40497/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp5216438400756976037.tmp
22/06/11 17:43:06 INFO Utils: /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp5216438400756976037.tmp has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:43:06 INFO Executor: Adding file:/tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.slf4j_slf4j-api-1.7.30.jar to class loader
22/06/11 17:43:06 INFO Executor: Fetching spark://d86e382532b9:40497/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Fetching spark://d86e382532b9:40497/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp3603090614999004596.tmp
22/06/11 17:43:06 INFO Utils: /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp3603090614999004596.tmp has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
22/06/11 17:43:06 INFO Executor: Adding file:/tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to class loader
22/06/11 17:43:06 INFO Executor: Fetching spark://d86e382532b9:40497/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Fetching spark://d86e382532b9:40497/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp2999970898007627535.tmp
22/06/11 17:43:06 INFO Utils: /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp2999970898007627535.tmp has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:43:06 INFO Executor: Adding file:/tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.apache.commons_commons-pool2-2.6.2.jar to class loader
22/06/11 17:43:06 INFO Executor: Fetching spark://d86e382532b9:40497/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Fetching spark://d86e382532b9:40497/jars/org.apache.kafka_kafka-clients-2.4.1.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp9073773470979439640.tmp
22/06/11 17:43:06 INFO Utils: /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp9073773470979439640.tmp has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.apache.kafka_kafka-clients-2.4.1.jar
22/06/11 17:43:06 INFO Executor: Adding file:/tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.apache.kafka_kafka-clients-2.4.1.jar to class loader
22/06/11 17:43:06 INFO Executor: Fetching spark://d86e382532b9:40497/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Fetching spark://d86e382532b9:40497/jars/com.github.luben_zstd-jni-1.4.4-3.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp6510461514315031390.tmp
22/06/11 17:43:06 INFO Utils: /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp6510461514315031390.tmp has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/com.github.luben_zstd-jni-1.4.4-3.jar
22/06/11 17:43:06 INFO Executor: Adding file:/tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/com.github.luben_zstd-jni-1.4.4-3.jar to class loader
22/06/11 17:43:06 INFO Executor: Fetching spark://d86e382532b9:40497/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654969386125
22/06/11 17:43:06 INFO Utils: Fetching spark://d86e382532b9:40497/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp7111351614316004154.tmp
22/06/11 17:43:06 INFO Utils: /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/fetchFileTemp7111351614316004154.tmp has been previously copied to /tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:43:06 INFO Executor: Adding file:/tmp/spark-9d9a4302-15b3-4b95-a58e-8a35746f9683/userFiles-bc59f6c3-0c65-4afc-8609-0528e51a4bca/org.spark-project.spark_unused-1.0.0.jar to class loader
22/06/11 17:43:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37985.
22/06/11 17:43:06 INFO NettyBlockTransferService: Server created on d86e382532b9:37985
22/06/11 17:43:06 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/11 17:43:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d86e382532b9, 37985, None)
22/06/11 17:43:06 INFO BlockManagerMasterEndpoint: Registering block manager d86e382532b9:37985 with 366.3 MiB RAM, BlockManagerId(driver, d86e382532b9, 37985, None)
22/06/11 17:43:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d86e382532b9, 37985, None)
22/06/11 17:43:06 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d86e382532b9, 37985, None)
22/06/11 17:43:07 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/06/11 17:43:07 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
22/06/11 17:43:09 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
22/06/11 17:43:09 ERROR MicroBatchExecution: Query [id = 017363b8-5645-4409-b186-f7817067c1f5, runId = e8688061-69c1-493c-ad76-8e57341d93f8] terminated with error
java.lang.NoClassDefFoundError: org/apache/spark/sql/internal/connector/SupportsStreamingUpdate
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:756)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:473)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable.newWriteBuilder(KafkaSourceProvider.scala:397)
	at org.apache.spark.sql.execution.streaming.StreamExecution.createStreamingWrite(StreamExecution.scala:590)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.logicalPlan$lzycompute(MicroBatchExecution.scala:140)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.logicalPlan(MicroBatchExecution.scala:59)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:286)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:209)
Caused by: java.lang.ClassNotFoundException: org.apache.spark.sql.internal.connector.SupportsStreamingUpdate
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more
Exception in thread "stream execution thread for [id = 017363b8-5645-4409-b186-f7817067c1f5, runId = e8688061-69c1-493c-ad76-8e57341d93f8]" java.lang.NoClassDefFoundError: org/apache/spark/sql/internal/connector/SupportsStreamingUpdate
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:756)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:473)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable.newWriteBuilder(KafkaSourceProvider.scala:397)
	at org.apache.spark.sql.execution.streaming.StreamExecution.createStreamingWrite(StreamExecution.scala:590)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.logicalPlan$lzycompute(MicroBatchExecution.scala:140)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.logicalPlan(MicroBatchExecution.scala:59)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:286)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:209)
Caused by: java.lang.ClassNotFoundException: org.apache.spark.sql.internal.connector.SupportsStreamingUpdate
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more
Traceback (most recent call last):
  File "/home/workspace/sparkpykafkajoin.py", line 200, in <module>
    customerRiskStreamingDF.selectExpr("to_json(struct(*)) AS value")\
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming.py", line 101, in awaitTermination
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.StreamingQueryException: org/apache/spark/sql/internal/connector/SupportsStreamingUpdate
=== Streaming Query ===
Identifier: [id = 017363b8-5645-4409-b186-f7817067c1f5, runId = e8688061-69c1-493c-ad76-8e57341d93f8]
Current Committed Offsets: {}
Current Available Offsets: {}

Current State: INITIALIZING
Thread State: RUNNABLE
:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.13 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-10dda145-24bd-4ce1-b126-7ce36ee87ecb;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.13;3.2.1 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.2.1 in central
	found org.apache.kafka#kafka-clients;2.8.0 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.8.4 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.apache.hadoop#hadoop-client-runtime;3.3.1 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.hadoop#hadoop-client-api;3.3.1 in central
	found org.apache.htrace#htrace-core4;4.1.0-incubating in central
	found commons-logging#commons-logging;1.1.3 in central
	found com.google.code.findbugs#jsr305;3.0.0 in central
	found org.scala-lang.modules#scala-parallel-collections_2.13;1.0.3 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.13/3.2.1/spark-sql-kafka-0-10_2.13-3.2.1.jar ...
	[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.13;3.2.1!spark-sql-kafka-0-10_2.13.jar (196ms)
downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.13/3.2.1/spark-token-provider-kafka-0-10_2.13-3.2.1.jar ...
	[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.2.1!spark-token-provider-kafka-0-10_2.13.jar (93ms)
downloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-parallel-collections_2.13/1.0.3/scala-parallel-collections_2.13-1.0.3.jar ...
	[SUCCESSFUL ] org.scala-lang.modules#scala-parallel-collections_2.13;1.0.3!scala-parallel-collections_2.13.jar (192ms)
downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/2.8.0/kafka-clients-2.8.0.jar ...
	[SUCCESSFUL ] org.apache.kafka#kafka-clients;2.8.0!kafka-clients.jar (321ms)
downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar ...
	[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.0!jsr305.jar (267ms)
downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar ...
	[SUCCESSFUL ] org.apache.hadoop#hadoop-client-runtime;3.3.1!hadoop-client-runtime.jar (1352ms)
downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.8.4/snappy-java-1.1.8.4.jar ...
	[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.8.4!snappy-java.jar(bundle) (160ms)
downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-api/3.3.1/hadoop-client-api-3.3.1.jar ...
	[SUCCESSFUL ] org.apache.hadoop#hadoop-client-api;3.3.1!hadoop-client-api.jar (832ms)
downloading https://repo1.maven.org/maven2/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar ...
	[SUCCESSFUL ] org.apache.htrace#htrace-core4;4.1.0-incubating!htrace-core4.jar (145ms)
downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...
	[SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (91ms)
:: resolution report :: resolve 16019ms :: artifacts dl 3725ms
	:: modules in use:
	com.google.code.findbugs#jsr305;3.0.0 from central in [default]
	commons-logging#commons-logging;1.1.3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.hadoop#hadoop-client-api;3.3.1 from central in [default]
	org.apache.hadoop#hadoop-client-runtime;3.3.1 from central in [default]
	org.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]
	org.apache.kafka#kafka-clients;2.8.0 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.13;3.2.1 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.2.1 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.scala-lang.modules#scala-parallel-collections_2.13;1.0.3 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.8.4 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   14  |   10  |   10  |   0   ||   14  |   10  |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-10dda145-24bd-4ce1-b126-7ce36ee87ecb
	confs: [default]
	10 artifacts copied, 4 already retrieved (59480kB/744ms)
22/06/11 17:46:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/11 17:46:32 INFO SparkContext: Running Spark version 3.2.1
22/06/11 17:46:32 INFO ResourceUtils: ==============================================================
22/06/11 17:46:32 INFO ResourceUtils: No custom resources configured for spark.driver.
22/06/11 17:46:32 INFO ResourceUtils: ==============================================================
22/06/11 17:46:32 INFO SparkContext: Submitted application: Evaluate-Human-Balance
22/06/11 17:46:32 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/06/11 17:46:32 INFO ResourceProfile: Limiting resource is cpu
22/06/11 17:46:32 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/06/11 17:46:32 INFO SecurityManager: Changing view acls to: spark
22/06/11 17:46:32 INFO SecurityManager: Changing modify acls to: spark
22/06/11 17:46:32 INFO SecurityManager: Changing view acls groups to: 
22/06/11 17:46:32 INFO SecurityManager: Changing modify acls groups to: 
22/06/11 17:46:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
22/06/11 17:46:32 INFO Utils: Successfully started service 'sparkDriver' on port 36465.
22/06/11 17:46:32 INFO SparkEnv: Registering MapOutputTracker
22/06/11 17:46:32 INFO SparkEnv: Registering BlockManagerMaster
22/06/11 17:46:32 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/11 17:46:32 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/11 17:46:32 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/06/11 17:46:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6e1c6d24-6a41-4581-8551-ab27c4d0812a
22/06/11 17:46:32 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/06/11 17:46:32 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/11 17:46:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/11 17:46:33 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://d86e382532b9:4040
22/06/11 17:46:33 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar at spark://d86e382532b9:36465/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar at spark://d86e382532b9:36465/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar at spark://d86e382532b9:36465/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar at spark://d86e382532b9:36465/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://d86e382532b9:36465/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://d86e382532b9:36465/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://d86e382532b9:36465/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar at spark://d86e382532b9:36465/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://d86e382532b9:36465/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar at spark://d86e382532b9:36465/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://d86e382532b9:36465/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar at spark://d86e382532b9:36465/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar at spark://d86e382532b9:36465/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://d86e382532b9:36465/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:46:33 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:46:33 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar at file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar
22/06/11 17:46:33 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.kafka_kafka-clients-2.8.0.jar
22/06/11 17:46:33 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/com.google.code.findbugs_jsr305-3.0.0.jar
22/06/11 17:46:33 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:46:33 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:46:33 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar
22/06/11 17:46:33 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:46:33 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar at file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.xerial.snappy_snappy-java-1.1.8.4.jar
22/06/11 17:46:33 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:46:33 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.hadoop_hadoop-client-api-3.3.1.jar
22/06/11 17:46:33 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.htrace_htrace-core4-4.1.0-incubating.jar
22/06/11 17:46:33 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/commons-logging_commons-logging-1.1.3.jar
22/06/11 17:46:33 INFO Executor: Starting executor ID driver on host d86e382532b9
22/06/11 17:46:33 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: /opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/commons-logging_commons-logging-1.1.3.jar
22/06/11 17:46:33 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.kafka_kafka-clients-2.8.0.jar
22/06/11 17:46:33 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:46:33 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.hadoop_hadoop-client-api-3.3.1.jar
22/06/11 17:46:33 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar
22/06/11 17:46:33 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: /opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/com.google.code.findbugs_jsr305-3.0.0.jar
22/06/11 17:46:33 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:46:33 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.htrace_htrace-core4-4.1.0-incubating.jar
22/06/11 17:46:33 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.xerial.snappy_snappy-java-1.1.8.4.jar
22/06/11 17:46:33 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:46:33 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:46:33 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:46:33 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:46:33 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar
22/06/11 17:46:33 INFO Executor: Fetching spark://d86e382532b9:36465/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO TransportClientFactory: Successfully created connection to d86e382532b9/172.22.0.4:36465 after 16 ms (0 ms spent in bootstraps)
22/06/11 17:46:33 INFO Utils: Fetching spark://d86e382532b9:36465/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp3824447634300048715.tmp
22/06/11 17:46:33 INFO Utils: /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp3824447634300048715.tmp has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.hadoop_hadoop-client-api-3.3.1.jar
22/06/11 17:46:33 INFO Executor: Adding file:/tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.hadoop_hadoop-client-api-3.3.1.jar to class loader
22/06/11 17:46:33 INFO Executor: Fetching spark://d86e382532b9:36465/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Fetching spark://d86e382532b9:36465/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp4735819380478020194.tmp
22/06/11 17:46:33 INFO Utils: /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp4735819380478020194.tmp has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.htrace_htrace-core4-4.1.0-incubating.jar
22/06/11 17:46:33 INFO Executor: Adding file:/tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.htrace_htrace-core4-4.1.0-incubating.jar to class loader
22/06/11 17:46:33 INFO Executor: Fetching spark://d86e382532b9:36465/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Fetching spark://d86e382532b9:36465/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp3763483055147262154.tmp
22/06/11 17:46:33 INFO Utils: /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp3763483055147262154.tmp has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/commons-logging_commons-logging-1.1.3.jar
22/06/11 17:46:33 INFO Executor: Adding file:/tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/commons-logging_commons-logging-1.1.3.jar to class loader
22/06/11 17:46:33 INFO Executor: Fetching spark://d86e382532b9:36465/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Fetching spark://d86e382532b9:36465/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp8745081532821027450.tmp
22/06/11 17:46:33 INFO Utils: /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp8745081532821027450.tmp has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:46:33 INFO Executor: Adding file:/tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar to class loader
22/06/11 17:46:33 INFO Executor: Fetching spark://d86e382532b9:36465/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Fetching spark://d86e382532b9:36465/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp3129289846474547555.tmp
22/06/11 17:46:33 INFO Utils: /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp3129289846474547555.tmp has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar
22/06/11 17:46:33 INFO Executor: Adding file:/tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar to class loader
22/06/11 17:46:33 INFO Executor: Fetching spark://d86e382532b9:36465/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Fetching spark://d86e382532b9:36465/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp2264825035213318780.tmp
22/06/11 17:46:33 INFO Utils: /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp2264825035213318780.tmp has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:46:33 INFO Executor: Adding file:/tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.lz4_lz4-java-1.7.1.jar to class loader
22/06/11 17:46:33 INFO Executor: Fetching spark://d86e382532b9:36465/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Fetching spark://d86e382532b9:36465/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp4630861686110418395.tmp
22/06/11 17:46:33 INFO Utils: /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp4630861686110418395.tmp has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:46:33 INFO Executor: Adding file:/tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.commons_commons-pool2-2.6.2.jar to class loader
22/06/11 17:46:33 INFO Executor: Fetching spark://d86e382532b9:36465/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Fetching spark://d86e382532b9:36465/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp6281875727866690913.tmp
22/06/11 17:46:33 INFO Utils: /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp6281875727866690913.tmp has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:46:33 INFO Executor: Adding file:/tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.spark-project.spark_unused-1.0.0.jar to class loader
22/06/11 17:46:33 INFO Executor: Fetching spark://d86e382532b9:36465/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Fetching spark://d86e382532b9:36465/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp2778741234599720162.tmp
22/06/11 17:46:33 INFO Utils: /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp2778741234599720162.tmp has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:46:33 INFO Executor: Adding file:/tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar to class loader
22/06/11 17:46:33 INFO Executor: Fetching spark://d86e382532b9:36465/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Fetching spark://d86e382532b9:36465/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp104870738621797882.tmp
22/06/11 17:46:33 INFO Utils: /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp104870738621797882.tmp has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar
22/06/11 17:46:33 INFO Executor: Adding file:/tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar to class loader
22/06/11 17:46:33 INFO Executor: Fetching spark://d86e382532b9:36465/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Fetching spark://d86e382532b9:36465/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp2244861041923780613.tmp
22/06/11 17:46:33 INFO Utils: /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp2244861041923780613.tmp has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:46:33 INFO Executor: Adding file:/tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.slf4j_slf4j-api-1.7.30.jar to class loader
22/06/11 17:46:33 INFO Executor: Fetching spark://d86e382532b9:36465/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Fetching spark://d86e382532b9:36465/jars/org.apache.kafka_kafka-clients-2.8.0.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp3600513544518033230.tmp
22/06/11 17:46:33 INFO Utils: /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp3600513544518033230.tmp has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.kafka_kafka-clients-2.8.0.jar
22/06/11 17:46:33 INFO Executor: Adding file:/tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.apache.kafka_kafka-clients-2.8.0.jar to class loader
22/06/11 17:46:33 INFO Executor: Fetching spark://d86e382532b9:36465/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Fetching spark://d86e382532b9:36465/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp4032633912849666115.tmp
22/06/11 17:46:33 INFO Utils: /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp4032633912849666115.tmp has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/com.google.code.findbugs_jsr305-3.0.0.jar
22/06/11 17:46:33 INFO Executor: Adding file:/tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/com.google.code.findbugs_jsr305-3.0.0.jar to class loader
22/06/11 17:46:33 INFO Executor: Fetching spark://d86e382532b9:36465/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654969592555
22/06/11 17:46:33 INFO Utils: Fetching spark://d86e382532b9:36465/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp171802071029208472.tmp
22/06/11 17:46:33 INFO Utils: /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/fetchFileTemp171802071029208472.tmp has been previously copied to /tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.xerial.snappy_snappy-java-1.1.8.4.jar
22/06/11 17:46:33 INFO Executor: Adding file:/tmp/spark-a615c860-e567-4be1-81e8-c66c788507a4/userFiles-8b577592-ed95-42e0-a501-45d57e747ccc/org.xerial.snappy_snappy-java-1.1.8.4.jar to class loader
22/06/11 17:46:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33835.
22/06/11 17:46:33 INFO NettyBlockTransferService: Server created on d86e382532b9:33835
22/06/11 17:46:33 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/11 17:46:33 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d86e382532b9, 33835, None)
22/06/11 17:46:33 INFO BlockManagerMasterEndpoint: Registering block manager d86e382532b9:33835 with 366.3 MiB RAM, BlockManagerId(driver, d86e382532b9, 33835, None)
22/06/11 17:46:33 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d86e382532b9, 33835, None)
22/06/11 17:46:33 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d86e382532b9, 33835, None)
22/06/11 17:46:33 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/06/11 17:46:33 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
Traceback (most recent call last):
  File "/home/workspace/sparkpykafkajoin.py", line 55, in <module>
    redisServerRawStreamingDF = spark                          \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming.py", line 454, in load
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o32.load.
: java.lang.NoClassDefFoundError: scala/$less$colon$less
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.org$apache$spark$sql$kafka010$KafkaSourceProvider$$validateStreamOptions(KafkaSourceProvider.scala:338)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.sourceSchema(KafkaSourceProvider.scala:71)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceSchema(DataSource.scala:236)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo$lzycompute(DataSource.scala:118)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo(DataSource.scala:118)
	at org.apache.spark.sql.execution.streaming.StreamingRelation$.apply(StreamingRelation.scala:34)
	at org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:167)
	at org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:143)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: scala.$less$colon$less
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more

:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.13 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-f4e7e36e-7b38-471c-a6ac-3e601127397d;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.13;3.2.1 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.2.1 in central
	found org.apache.kafka#kafka-clients;2.8.0 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.8.4 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.apache.hadoop#hadoop-client-runtime;3.3.1 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.hadoop#hadoop-client-api;3.3.1 in central
	found org.apache.htrace#htrace-core4;4.1.0-incubating in central
	found commons-logging#commons-logging;1.1.3 in central
	found com.google.code.findbugs#jsr305;3.0.0 in central
	found org.scala-lang.modules#scala-parallel-collections_2.13;1.0.3 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 496ms :: artifacts dl 64ms
	:: modules in use:
	com.google.code.findbugs#jsr305;3.0.0 from central in [default]
	commons-logging#commons-logging;1.1.3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.hadoop#hadoop-client-api;3.3.1 from central in [default]
	org.apache.hadoop#hadoop-client-runtime;3.3.1 from central in [default]
	org.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]
	org.apache.kafka#kafka-clients;2.8.0 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.13;3.2.1 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.2.1 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.scala-lang.modules#scala-parallel-collections_2.13;1.0.3 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.8.4 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   14  |   0   |   0   |   0   ||   14  |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-f4e7e36e-7b38-471c-a6ac-3e601127397d
	confs: [default]
	0 artifacts copied, 14 already retrieved (0kB/12ms)
22/06/11 17:48:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/11 17:48:27 INFO SparkContext: Running Spark version 3.2.1
22/06/11 17:48:27 INFO ResourceUtils: ==============================================================
22/06/11 17:48:27 INFO ResourceUtils: No custom resources configured for spark.driver.
22/06/11 17:48:27 INFO ResourceUtils: ==============================================================
22/06/11 17:48:27 INFO SparkContext: Submitted application: Evaluate-Human-Balance
22/06/11 17:48:27 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/06/11 17:48:27 INFO ResourceProfile: Limiting resource is cpu
22/06/11 17:48:27 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/06/11 17:48:27 INFO SecurityManager: Changing view acls to: spark
22/06/11 17:48:27 INFO SecurityManager: Changing modify acls to: spark
22/06/11 17:48:27 INFO SecurityManager: Changing view acls groups to: 
22/06/11 17:48:27 INFO SecurityManager: Changing modify acls groups to: 
22/06/11 17:48:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
22/06/11 17:48:27 INFO Utils: Successfully started service 'sparkDriver' on port 46409.
22/06/11 17:48:27 INFO SparkEnv: Registering MapOutputTracker
22/06/11 17:48:27 INFO SparkEnv: Registering BlockManagerMaster
22/06/11 17:48:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/11 17:48:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/11 17:48:27 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/06/11 17:48:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-88d62021-f7a9-4190-99c0-54242a7247a4
22/06/11 17:48:27 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/06/11 17:48:27 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/11 17:48:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/11 17:48:27 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://d86e382532b9:4040
22/06/11 17:48:27 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar at spark://d86e382532b9:46409/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar at spark://d86e382532b9:46409/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar at spark://d86e382532b9:46409/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar at spark://d86e382532b9:46409/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://d86e382532b9:46409/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://d86e382532b9:46409/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://d86e382532b9:46409/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar at spark://d86e382532b9:46409/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://d86e382532b9:46409/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar at spark://d86e382532b9:46409/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://d86e382532b9:46409/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar at spark://d86e382532b9:46409/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar at spark://d86e382532b9:46409/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://d86e382532b9:46409/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:48:27 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:48:27 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar at file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar
22/06/11 17:48:27 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.kafka_kafka-clients-2.8.0.jar
22/06/11 17:48:27 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/com.google.code.findbugs_jsr305-3.0.0.jar
22/06/11 17:48:27 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:48:27 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:48:27 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654969707477
22/06/11 17:48:27 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar
22/06/11 17:48:28 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:48:28 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar at file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.xerial.snappy_snappy-java-1.1.8.4.jar
22/06/11 17:48:28 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:48:28 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.hadoop_hadoop-client-api-3.3.1.jar
22/06/11 17:48:28 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.htrace_htrace-core4-4.1.0-incubating.jar
22/06/11 17:48:28 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/commons-logging_commons-logging-1.1.3.jar
22/06/11 17:48:28 INFO Executor: Starting executor ID driver on host d86e382532b9
22/06/11 17:48:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/commons-logging_commons-logging-1.1.3.jar
22/06/11 17:48:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.kafka_kafka-clients-2.8.0.jar
22/06/11 17:48:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:48:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.hadoop_hadoop-client-api-3.3.1.jar
22/06/11 17:48:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar
22/06/11 17:48:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/com.google.code.findbugs_jsr305-3.0.0.jar
22/06/11 17:48:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:48:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.htrace_htrace-core4-4.1.0-incubating.jar
22/06/11 17:48:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.xerial.snappy_snappy-java-1.1.8.4.jar
22/06/11 17:48:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:48:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:48:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:48:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:48:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar
22/06/11 17:48:28 INFO Executor: Fetching spark://d86e382532b9:46409/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO TransportClientFactory: Successfully created connection to d86e382532b9/172.22.0.4:46409 after 16 ms (0 ms spent in bootstraps)
22/06/11 17:48:28 INFO Utils: Fetching spark://d86e382532b9:46409/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp681081562190221156.tmp
22/06/11 17:48:28 INFO Utils: /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp681081562190221156.tmp has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:48:28 INFO Executor: Adding file:/tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar to class loader
22/06/11 17:48:28 INFO Executor: Fetching spark://d86e382532b9:46409/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Fetching spark://d86e382532b9:46409/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp5699648022707735158.tmp
22/06/11 17:48:28 INFO Utils: /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp5699648022707735158.tmp has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.hadoop_hadoop-client-api-3.3.1.jar
22/06/11 17:48:28 INFO Executor: Adding file:/tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.hadoop_hadoop-client-api-3.3.1.jar to class loader
22/06/11 17:48:28 INFO Executor: Fetching spark://d86e382532b9:46409/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Fetching spark://d86e382532b9:46409/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp8749089668273974555.tmp
22/06/11 17:48:28 INFO Utils: /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp8749089668273974555.tmp has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/com.google.code.findbugs_jsr305-3.0.0.jar
22/06/11 17:48:28 INFO Executor: Adding file:/tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/com.google.code.findbugs_jsr305-3.0.0.jar to class loader
22/06/11 17:48:28 INFO Executor: Fetching spark://d86e382532b9:46409/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Fetching spark://d86e382532b9:46409/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp4084070740304532932.tmp
22/06/11 17:48:28 INFO Utils: /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp4084070740304532932.tmp has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar
22/06/11 17:48:28 INFO Executor: Adding file:/tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar to class loader
22/06/11 17:48:28 INFO Executor: Fetching spark://d86e382532b9:46409/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Fetching spark://d86e382532b9:46409/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp5768257681785233804.tmp
22/06/11 17:48:28 INFO Utils: /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp5768257681785233804.tmp has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:48:28 INFO Executor: Adding file:/tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.spark-project.spark_unused-1.0.0.jar to class loader
22/06/11 17:48:28 INFO Executor: Fetching spark://d86e382532b9:46409/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Fetching spark://d86e382532b9:46409/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp7996616354239704575.tmp
22/06/11 17:48:28 INFO Utils: /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp7996616354239704575.tmp has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.htrace_htrace-core4-4.1.0-incubating.jar
22/06/11 17:48:28 INFO Executor: Adding file:/tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.htrace_htrace-core4-4.1.0-incubating.jar to class loader
22/06/11 17:48:28 INFO Executor: Fetching spark://d86e382532b9:46409/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Fetching spark://d86e382532b9:46409/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp4976856824574765419.tmp
22/06/11 17:48:28 INFO Utils: /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp4976856824574765419.tmp has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:48:28 INFO Executor: Adding file:/tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.slf4j_slf4j-api-1.7.30.jar to class loader
22/06/11 17:48:28 INFO Executor: Fetching spark://d86e382532b9:46409/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Fetching spark://d86e382532b9:46409/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp4531639914887228191.tmp
22/06/11 17:48:28 INFO Utils: /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp4531639914887228191.tmp has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:48:28 INFO Executor: Adding file:/tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar to class loader
22/06/11 17:48:28 INFO Executor: Fetching spark://d86e382532b9:46409/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Fetching spark://d86e382532b9:46409/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp5404841955856163104.tmp
22/06/11 17:48:28 INFO Utils: /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp5404841955856163104.tmp has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:48:28 INFO Executor: Adding file:/tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.commons_commons-pool2-2.6.2.jar to class loader
22/06/11 17:48:28 INFO Executor: Fetching spark://d86e382532b9:46409/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Fetching spark://d86e382532b9:46409/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp5678156389766946158.tmp
22/06/11 17:48:28 INFO Utils: /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp5678156389766946158.tmp has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar
22/06/11 17:48:28 INFO Executor: Adding file:/tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar to class loader
22/06/11 17:48:28 INFO Executor: Fetching spark://d86e382532b9:46409/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Fetching spark://d86e382532b9:46409/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp4579209421930009059.tmp
22/06/11 17:48:28 INFO Utils: /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp4579209421930009059.tmp has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.xerial.snappy_snappy-java-1.1.8.4.jar
22/06/11 17:48:28 INFO Executor: Adding file:/tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.xerial.snappy_snappy-java-1.1.8.4.jar to class loader
22/06/11 17:48:28 INFO Executor: Fetching spark://d86e382532b9:46409/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Fetching spark://d86e382532b9:46409/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp6931151553945444145.tmp
22/06/11 17:48:28 INFO Utils: /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp6931151553945444145.tmp has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/commons-logging_commons-logging-1.1.3.jar
22/06/11 17:48:28 INFO Executor: Adding file:/tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/commons-logging_commons-logging-1.1.3.jar to class loader
22/06/11 17:48:28 INFO Executor: Fetching spark://d86e382532b9:46409/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Fetching spark://d86e382532b9:46409/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp2283423336019936816.tmp
22/06/11 17:48:28 INFO Utils: /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp2283423336019936816.tmp has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:48:28 INFO Executor: Adding file:/tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.lz4_lz4-java-1.7.1.jar to class loader
22/06/11 17:48:28 INFO Executor: Fetching spark://d86e382532b9:46409/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654969707477
22/06/11 17:48:28 INFO Utils: Fetching spark://d86e382532b9:46409/jars/org.apache.kafka_kafka-clients-2.8.0.jar to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp267254947300316580.tmp
22/06/11 17:48:28 INFO Utils: /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/fetchFileTemp267254947300316580.tmp has been previously copied to /tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.kafka_kafka-clients-2.8.0.jar
22/06/11 17:48:28 INFO Executor: Adding file:/tmp/spark-91349331-a725-401c-bbc2-90eb1c1a834d/userFiles-702dac40-2193-43af-8fa0-92e85b5aa8bf/org.apache.kafka_kafka-clients-2.8.0.jar to class loader
22/06/11 17:48:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43169.
22/06/11 17:48:28 INFO NettyBlockTransferService: Server created on d86e382532b9:43169
22/06/11 17:48:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/11 17:48:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d86e382532b9, 43169, None)
22/06/11 17:48:28 INFO BlockManagerMasterEndpoint: Registering block manager d86e382532b9:43169 with 366.3 MiB RAM, BlockManagerId(driver, d86e382532b9, 43169, None)
22/06/11 17:48:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d86e382532b9, 43169, None)
22/06/11 17:48:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d86e382532b9, 43169, None)
22/06/11 17:48:28 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/06/11 17:48:28 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
Traceback (most recent call last):
  File "/home/workspace/sparkpykafkajoin.py", line 55, in <module>
    redisServerRawStreamingDF = spark\
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming.py", line 454, in load
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o32.load.
: java.lang.NoClassDefFoundError: scala/$less$colon$less
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.org$apache$spark$sql$kafka010$KafkaSourceProvider$$validateStreamOptions(KafkaSourceProvider.scala:338)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.sourceSchema(KafkaSourceProvider.scala:71)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceSchema(DataSource.scala:236)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo$lzycompute(DataSource.scala:118)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo(DataSource.scala:118)
	at org.apache.spark.sql.execution.streaming.StreamingRelation$.apply(StreamingRelation.scala:34)
	at org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:167)
	at org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:143)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: scala.$less$colon$less
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more

:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.13 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-410dd0e1-3a6d-4142-a670-8b16e510ee82;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.13;3.2.1 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.2.1 in central
	found org.apache.kafka#kafka-clients;2.8.0 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.8.4 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.apache.hadoop#hadoop-client-runtime;3.3.1 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.hadoop#hadoop-client-api;3.3.1 in central
	found org.apache.htrace#htrace-core4;4.1.0-incubating in central
	found commons-logging#commons-logging;1.1.3 in central
	found com.google.code.findbugs#jsr305;3.0.0 in central
	found org.scala-lang.modules#scala-parallel-collections_2.13;1.0.3 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 673ms :: artifacts dl 88ms
	:: modules in use:
	com.google.code.findbugs#jsr305;3.0.0 from central in [default]
	commons-logging#commons-logging;1.1.3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.hadoop#hadoop-client-api;3.3.1 from central in [default]
	org.apache.hadoop#hadoop-client-runtime;3.3.1 from central in [default]
	org.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]
	org.apache.kafka#kafka-clients;2.8.0 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.13;3.2.1 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.2.1 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.scala-lang.modules#scala-parallel-collections_2.13;1.0.3 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.8.4 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   14  |   0   |   0   |   0   ||   14  |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-410dd0e1-3a6d-4142-a670-8b16e510ee82
	confs: [default]
	0 artifacts copied, 14 already retrieved (0kB/22ms)
22/06/11 17:58:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/11 17:58:17 INFO SparkContext: Running Spark version 3.2.1
22/06/11 17:58:17 INFO ResourceUtils: ==============================================================
22/06/11 17:58:17 INFO ResourceUtils: No custom resources configured for spark.driver.
22/06/11 17:58:17 INFO ResourceUtils: ==============================================================
22/06/11 17:58:17 INFO SparkContext: Submitted application: Evaluate-Human-Balance
22/06/11 17:58:17 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/06/11 17:58:17 INFO ResourceProfile: Limiting resource is cpu
22/06/11 17:58:17 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/06/11 17:58:17 INFO SecurityManager: Changing view acls to: spark
22/06/11 17:58:17 INFO SecurityManager: Changing modify acls to: spark
22/06/11 17:58:17 INFO SecurityManager: Changing view acls groups to: 
22/06/11 17:58:17 INFO SecurityManager: Changing modify acls groups to: 
22/06/11 17:58:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
22/06/11 17:58:18 INFO Utils: Successfully started service 'sparkDriver' on port 43511.
22/06/11 17:58:18 INFO SparkEnv: Registering MapOutputTracker
22/06/11 17:58:18 INFO SparkEnv: Registering BlockManagerMaster
22/06/11 17:58:18 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/11 17:58:18 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/11 17:58:18 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/06/11 17:58:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2d25e444-6ec3-4e8f-a04c-6db7e74e234f
22/06/11 17:58:18 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/06/11 17:58:18 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/11 17:58:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/11 17:58:18 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://d86e382532b9:4040
22/06/11 17:58:18 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar at spark://d86e382532b9:43511/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar at spark://d86e382532b9:43511/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar at spark://d86e382532b9:43511/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar at spark://d86e382532b9:43511/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://d86e382532b9:43511/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://d86e382532b9:43511/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://d86e382532b9:43511/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar at spark://d86e382532b9:43511/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://d86e382532b9:43511/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar at spark://d86e382532b9:43511/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://d86e382532b9:43511/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar at spark://d86e382532b9:43511/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar at spark://d86e382532b9:43511/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://d86e382532b9:43511/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:58:18 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:58:18 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar at file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar
22/06/11 17:58:18 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.kafka_kafka-clients-2.8.0.jar
22/06/11 17:58:18 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/com.google.code.findbugs_jsr305-3.0.0.jar
22/06/11 17:58:18 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:58:18 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:58:18 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar
22/06/11 17:58:18 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:58:18 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar at file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.xerial.snappy_snappy-java-1.1.8.4.jar
22/06/11 17:58:18 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:58:18 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.hadoop_hadoop-client-api-3.3.1.jar
22/06/11 17:58:18 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.htrace_htrace-core4-4.1.0-incubating.jar
22/06/11 17:58:18 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/commons-logging_commons-logging-1.1.3.jar
22/06/11 17:58:18 INFO Executor: Starting executor ID driver on host d86e382532b9
22/06/11 17:58:18 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: /opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/commons-logging_commons-logging-1.1.3.jar
22/06/11 17:58:18 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.kafka_kafka-clients-2.8.0.jar
22/06/11 17:58:18 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:58:18 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.hadoop_hadoop-client-api-3.3.1.jar
22/06/11 17:58:18 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar
22/06/11 17:58:18 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: /opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/com.google.code.findbugs_jsr305-3.0.0.jar
22/06/11 17:58:18 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:58:18 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.htrace_htrace-core4-4.1.0-incubating.jar
22/06/11 17:58:18 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.xerial.snappy_snappy-java-1.1.8.4.jar
22/06/11 17:58:18 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:58:18 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:58:18 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:58:18 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:58:18 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar
22/06/11 17:58:18 INFO Executor: Fetching spark://d86e382532b9:43511/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654970297837
22/06/11 17:58:18 INFO TransportClientFactory: Successfully created connection to d86e382532b9/172.22.0.4:43511 after 20 ms (0 ms spent in bootstraps)
22/06/11 17:58:19 INFO Utils: Fetching spark://d86e382532b9:43511/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp3126283381791316782.tmp
22/06/11 17:58:19 INFO Utils: /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp3126283381791316782.tmp has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar
22/06/11 17:58:19 INFO Executor: Adding file:/tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar to class loader
22/06/11 17:58:19 INFO Executor: Fetching spark://d86e382532b9:43511/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970297837
22/06/11 17:58:19 INFO Utils: Fetching spark://d86e382532b9:43511/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp362823590738168374.tmp
22/06/11 17:58:19 INFO Utils: /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp362823590738168374.tmp has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.lz4_lz4-java-1.7.1.jar
22/06/11 17:58:19 INFO Executor: Adding file:/tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.lz4_lz4-java-1.7.1.jar to class loader
22/06/11 17:58:19 INFO Executor: Fetching spark://d86e382532b9:43511/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970297837
22/06/11 17:58:19 INFO Utils: Fetching spark://d86e382532b9:43511/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp3560175303983481983.tmp
22/06/11 17:58:19 INFO Utils: /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp3560175303983481983.tmp has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 17:58:19 INFO Executor: Adding file:/tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.commons_commons-pool2-2.6.2.jar to class loader
22/06/11 17:58:19 INFO Executor: Fetching spark://d86e382532b9:43511/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654970297837
22/06/11 17:58:19 INFO Utils: Fetching spark://d86e382532b9:43511/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp877331641645895607.tmp
22/06/11 17:58:19 INFO Utils: /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp877331641645895607.tmp has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/com.google.code.findbugs_jsr305-3.0.0.jar
22/06/11 17:58:19 INFO Executor: Adding file:/tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/com.google.code.findbugs_jsr305-3.0.0.jar to class loader
22/06/11 17:58:19 INFO Executor: Fetching spark://d86e382532b9:43511/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654970297837
22/06/11 17:58:19 INFO Utils: Fetching spark://d86e382532b9:43511/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp6528525217492612838.tmp
22/06/11 17:58:19 INFO Utils: /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp6528525217492612838.tmp has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.xerial.snappy_snappy-java-1.1.8.4.jar
22/06/11 17:58:19 INFO Executor: Adding file:/tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.xerial.snappy_snappy-java-1.1.8.4.jar to class loader
22/06/11 17:58:19 INFO Executor: Fetching spark://d86e382532b9:43511/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654970297837
22/06/11 17:58:19 INFO Utils: Fetching spark://d86e382532b9:43511/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp519264511707736788.tmp
22/06/11 17:58:19 INFO Utils: /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp519264511707736788.tmp has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar
22/06/11 17:58:19 INFO Executor: Adding file:/tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar to class loader
22/06/11 17:58:19 INFO Executor: Fetching spark://d86e382532b9:43511/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970297837
22/06/11 17:58:19 INFO Utils: Fetching spark://d86e382532b9:43511/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp3469575130494230168.tmp
22/06/11 17:58:19 INFO Utils: /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp3469575130494230168.tmp has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:58:19 INFO Executor: Adding file:/tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar to class loader
22/06/11 17:58:19 INFO Executor: Fetching spark://d86e382532b9:43511/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654970297837
22/06/11 17:58:19 INFO Utils: Fetching spark://d86e382532b9:43511/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp3495524770109773556.tmp
22/06/11 17:58:19 INFO Utils: /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp3495524770109773556.tmp has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.hadoop_hadoop-client-api-3.3.1.jar
22/06/11 17:58:19 INFO Executor: Adding file:/tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.hadoop_hadoop-client-api-3.3.1.jar to class loader
22/06/11 17:58:19 INFO Executor: Fetching spark://d86e382532b9:43511/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970297837
22/06/11 17:58:19 INFO Utils: Fetching spark://d86e382532b9:43511/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp1172920063008648534.tmp
22/06/11 17:58:19 INFO Utils: /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp1172920063008648534.tmp has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.spark-project.spark_unused-1.0.0.jar
22/06/11 17:58:19 INFO Executor: Adding file:/tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.spark-project.spark_unused-1.0.0.jar to class loader
22/06/11 17:58:19 INFO Executor: Fetching spark://d86e382532b9:43511/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654970297837
22/06/11 17:58:19 INFO Utils: Fetching spark://d86e382532b9:43511/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp3467744143551903608.tmp
22/06/11 17:58:19 INFO Utils: /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp3467744143551903608.tmp has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/commons-logging_commons-logging-1.1.3.jar
22/06/11 17:58:19 INFO Executor: Adding file:/tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/commons-logging_commons-logging-1.1.3.jar to class loader
22/06/11 17:58:19 INFO Executor: Fetching spark://d86e382532b9:43511/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654970297837
22/06/11 17:58:19 INFO Utils: Fetching spark://d86e382532b9:43511/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp1304808514701400471.tmp
22/06/11 17:58:19 INFO Utils: /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp1304808514701400471.tmp has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.htrace_htrace-core4-4.1.0-incubating.jar
22/06/11 17:58:19 INFO Executor: Adding file:/tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.htrace_htrace-core4-4.1.0-incubating.jar to class loader
22/06/11 17:58:19 INFO Executor: Fetching spark://d86e382532b9:43511/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970297837
22/06/11 17:58:19 INFO Utils: Fetching spark://d86e382532b9:43511/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp6406930112260763801.tmp
22/06/11 17:58:19 INFO Utils: /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp6406930112260763801.tmp has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar
22/06/11 17:58:19 INFO Executor: Adding file:/tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar to class loader
22/06/11 17:58:19 INFO Executor: Fetching spark://d86e382532b9:43511/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654970297837
22/06/11 17:58:19 INFO Utils: Fetching spark://d86e382532b9:43511/jars/org.apache.kafka_kafka-clients-2.8.0.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp43053695297580693.tmp
22/06/11 17:58:19 INFO Utils: /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp43053695297580693.tmp has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.kafka_kafka-clients-2.8.0.jar
22/06/11 17:58:19 INFO Executor: Adding file:/tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.apache.kafka_kafka-clients-2.8.0.jar to class loader
22/06/11 17:58:19 INFO Executor: Fetching spark://d86e382532b9:43511/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970297837
22/06/11 17:58:19 INFO Utils: Fetching spark://d86e382532b9:43511/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp724146016240011011.tmp
22/06/11 17:58:19 INFO Utils: /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/fetchFileTemp724146016240011011.tmp has been previously copied to /tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 17:58:19 INFO Executor: Adding file:/tmp/spark-cf47571f-4a7d-464e-9a73-6783e5ba03fa/userFiles-d39d3469-a9d3-44ca-a120-aeed5a5faf60/org.slf4j_slf4j-api-1.7.30.jar to class loader
22/06/11 17:58:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34013.
22/06/11 17:58:19 INFO NettyBlockTransferService: Server created on d86e382532b9:34013
22/06/11 17:58:19 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/11 17:58:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d86e382532b9, 34013, None)
22/06/11 17:58:19 INFO BlockManagerMasterEndpoint: Registering block manager d86e382532b9:34013 with 366.3 MiB RAM, BlockManagerId(driver, d86e382532b9, 34013, None)
22/06/11 17:58:19 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d86e382532b9, 34013, None)
22/06/11 17:58:19 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d86e382532b9, 34013, None)
22/06/11 17:58:19 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/06/11 17:58:19 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
Traceback (most recent call last):
  File "/home/workspace/sparkpykafkajoin.py", line 55, in <module>
    redisServerRawStreamingDF = spark\
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming.py", line 454, in load
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o32.load.
: java.lang.NoClassDefFoundError: scala/$less$colon$less
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.org$apache$spark$sql$kafka010$KafkaSourceProvider$$validateStreamOptions(KafkaSourceProvider.scala:338)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.sourceSchema(KafkaSourceProvider.scala:71)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceSchema(DataSource.scala:236)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo$lzycompute(DataSource.scala:118)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo(DataSource.scala:118)
	at org.apache.spark.sql.execution.streaming.StreamingRelation$.apply(StreamingRelation.scala:34)
	at org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:167)
	at org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:143)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: scala.$less$colon$less
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more

:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.13 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-9cecb228-c270-4ad3-b298-dfccaab4a1e8;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.13;3.2.1 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.2.1 in central
	found org.apache.kafka#kafka-clients;2.8.0 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.8.4 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.apache.hadoop#hadoop-client-runtime;3.3.1 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.hadoop#hadoop-client-api;3.3.1 in central
	found org.apache.htrace#htrace-core4;4.1.0-incubating in central
	found commons-logging#commons-logging;1.1.3 in central
	found com.google.code.findbugs#jsr305;3.0.0 in central
	found org.scala-lang.modules#scala-parallel-collections_2.13;1.0.3 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 649ms :: artifacts dl 99ms
	:: modules in use:
	com.google.code.findbugs#jsr305;3.0.0 from central in [default]
	commons-logging#commons-logging;1.1.3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.hadoop#hadoop-client-api;3.3.1 from central in [default]
	org.apache.hadoop#hadoop-client-runtime;3.3.1 from central in [default]
	org.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]
	org.apache.kafka#kafka-clients;2.8.0 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.13;3.2.1 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.2.1 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.scala-lang.modules#scala-parallel-collections_2.13;1.0.3 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.8.4 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   14  |   0   |   0   |   0   ||   14  |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-9cecb228-c270-4ad3-b298-dfccaab4a1e8
	confs: [default]
	0 artifacts copied, 14 already retrieved (0kB/10ms)
22/06/11 18:00:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/11 18:00:16 INFO SparkContext: Running Spark version 3.2.1
22/06/11 18:00:16 INFO ResourceUtils: ==============================================================
22/06/11 18:00:16 INFO ResourceUtils: No custom resources configured for spark.driver.
22/06/11 18:00:16 INFO ResourceUtils: ==============================================================
22/06/11 18:00:16 INFO SparkContext: Submitted application: Evaluate-Human-Balance
22/06/11 18:00:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/06/11 18:00:16 INFO ResourceProfile: Limiting resource is cpu
22/06/11 18:00:16 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/06/11 18:00:16 INFO SecurityManager: Changing view acls to: spark
22/06/11 18:00:16 INFO SecurityManager: Changing modify acls to: spark
22/06/11 18:00:16 INFO SecurityManager: Changing view acls groups to: 
22/06/11 18:00:16 INFO SecurityManager: Changing modify acls groups to: 
22/06/11 18:00:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
22/06/11 18:00:16 INFO Utils: Successfully started service 'sparkDriver' on port 41901.
22/06/11 18:00:16 INFO SparkEnv: Registering MapOutputTracker
22/06/11 18:00:16 INFO SparkEnv: Registering BlockManagerMaster
22/06/11 18:00:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/11 18:00:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/11 18:00:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/06/11 18:00:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-35f09aa0-cef1-4531-a24a-c8c5a0f26137
22/06/11 18:00:16 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/06/11 18:00:16 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/11 18:00:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/11 18:00:16 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://d86e382532b9:4040
22/06/11 18:00:16 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar at spark://d86e382532b9:41901/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar at spark://d86e382532b9:41901/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar at spark://d86e382532b9:41901/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar at spark://d86e382532b9:41901/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://d86e382532b9:41901/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://d86e382532b9:41901/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://d86e382532b9:41901/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar at spark://d86e382532b9:41901/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://d86e382532b9:41901/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar at spark://d86e382532b9:41901/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://d86e382532b9:41901/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar at spark://d86e382532b9:41901/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar at spark://d86e382532b9:41901/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://d86e382532b9:41901/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar
22/06/11 18:00:16 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar
22/06/11 18:00:16 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar at file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar
22/06/11 18:00:16 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.kafka_kafka-clients-2.8.0.jar
22/06/11 18:00:16 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/com.google.code.findbugs_jsr305-3.0.0.jar
22/06/11 18:00:16 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 18:00:16 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.spark-project.spark_unused-1.0.0.jar
22/06/11 18:00:16 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar
22/06/11 18:00:16 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.lz4_lz4-java-1.7.1.jar
22/06/11 18:00:16 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar at file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.xerial.snappy_snappy-java-1.1.8.4.jar
22/06/11 18:00:16 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 18:00:16 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.hadoop_hadoop-client-api-3.3.1.jar
22/06/11 18:00:16 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.htrace_htrace-core4-4.1.0-incubating.jar
22/06/11 18:00:16 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654970416173
22/06/11 18:00:16 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/commons-logging_commons-logging-1.1.3.jar
22/06/11 18:00:17 INFO Executor: Starting executor ID driver on host d86e382532b9
22/06/11 18:00:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/commons-logging_commons-logging-1.1.3.jar
22/06/11 18:00:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.kafka_kafka-clients-2.8.0.jar
22/06/11 18:00:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar
22/06/11 18:00:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.hadoop_hadoop-client-api-3.3.1.jar
22/06/11 18:00:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar
22/06/11 18:00:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/com.google.code.findbugs_jsr305-3.0.0.jar
22/06/11 18:00:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar
22/06/11 18:00:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.htrace_htrace-core4-4.1.0-incubating.jar
22/06/11 18:00:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.xerial.snappy_snappy-java-1.1.8.4.jar
22/06/11 18:00:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 18:00:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.spark-project.spark_unused-1.0.0.jar
22/06/11 18:00:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 18:00:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.lz4_lz4-java-1.7.1.jar
22/06/11 18:00:17 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar
22/06/11 18:00:17 INFO Executor: Fetching spark://d86e382532b9:41901/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO TransportClientFactory: Successfully created connection to d86e382532b9/172.22.0.4:41901 after 23 ms (0 ms spent in bootstraps)
22/06/11 18:00:17 INFO Utils: Fetching spark://d86e382532b9:41901/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp7770605896482396747.tmp
22/06/11 18:00:17 INFO Utils: /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp7770605896482396747.tmp has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.xerial.snappy_snappy-java-1.1.8.4.jar
22/06/11 18:00:17 INFO Executor: Adding file:/tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.xerial.snappy_snappy-java-1.1.8.4.jar to class loader
22/06/11 18:00:17 INFO Executor: Fetching spark://d86e382532b9:41901/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: Fetching spark://d86e382532b9:41901/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp5700279197145066587.tmp
22/06/11 18:00:17 INFO Utils: /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp5700279197145066587.tmp has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar
22/06/11 18:00:17 INFO Executor: Adding file:/tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar to class loader
22/06/11 18:00:17 INFO Executor: Fetching spark://d86e382532b9:41901/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: Fetching spark://d86e382532b9:41901/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp3191088248893698294.tmp
22/06/11 18:00:17 INFO Utils: /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp3191088248893698294.tmp has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar
22/06/11 18:00:17 INFO Executor: Adding file:/tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar to class loader
22/06/11 18:00:17 INFO Executor: Fetching spark://d86e382532b9:41901/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: Fetching spark://d86e382532b9:41901/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp2511635700466040631.tmp
22/06/11 18:00:17 INFO Utils: /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp2511635700466040631.tmp has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.lz4_lz4-java-1.7.1.jar
22/06/11 18:00:17 INFO Executor: Adding file:/tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.lz4_lz4-java-1.7.1.jar to class loader
22/06/11 18:00:17 INFO Executor: Fetching spark://d86e382532b9:41901/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: Fetching spark://d86e382532b9:41901/jars/org.apache.kafka_kafka-clients-2.8.0.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp412100745693066174.tmp
22/06/11 18:00:17 INFO Utils: /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp412100745693066174.tmp has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.kafka_kafka-clients-2.8.0.jar
22/06/11 18:00:17 INFO Executor: Adding file:/tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.kafka_kafka-clients-2.8.0.jar to class loader
22/06/11 18:00:17 INFO Executor: Fetching spark://d86e382532b9:41901/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: Fetching spark://d86e382532b9:41901/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp3031019056678721937.tmp
22/06/11 18:00:17 INFO Utils: /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp3031019056678721937.tmp has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/commons-logging_commons-logging-1.1.3.jar
22/06/11 18:00:17 INFO Executor: Adding file:/tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/commons-logging_commons-logging-1.1.3.jar to class loader
22/06/11 18:00:17 INFO Executor: Fetching spark://d86e382532b9:41901/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: Fetching spark://d86e382532b9:41901/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp7876130456443493672.tmp
22/06/11 18:00:17 INFO Utils: /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp7876130456443493672.tmp has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 18:00:17 INFO Executor: Adding file:/tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.commons_commons-pool2-2.6.2.jar to class loader
22/06/11 18:00:17 INFO Executor: Fetching spark://d86e382532b9:41901/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: Fetching spark://d86e382532b9:41901/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp4345682670150027399.tmp
22/06/11 18:00:17 INFO Utils: /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp4345682670150027399.tmp has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.hadoop_hadoop-client-api-3.3.1.jar
22/06/11 18:00:17 INFO Executor: Adding file:/tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.hadoop_hadoop-client-api-3.3.1.jar to class loader
22/06/11 18:00:17 INFO Executor: Fetching spark://d86e382532b9:41901/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: Fetching spark://d86e382532b9:41901/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp7361585515419773682.tmp
22/06/11 18:00:17 INFO Utils: /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp7361585515419773682.tmp has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar
22/06/11 18:00:17 INFO Executor: Adding file:/tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar to class loader
22/06/11 18:00:17 INFO Executor: Fetching spark://d86e382532b9:41901/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: Fetching spark://d86e382532b9:41901/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp5258290716557127666.tmp
22/06/11 18:00:17 INFO Utils: /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp5258290716557127666.tmp has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 18:00:17 INFO Executor: Adding file:/tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.slf4j_slf4j-api-1.7.30.jar to class loader
22/06/11 18:00:17 INFO Executor: Fetching spark://d86e382532b9:41901/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: Fetching spark://d86e382532b9:41901/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp4143682316644336983.tmp
22/06/11 18:00:17 INFO Utils: /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp4143682316644336983.tmp has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.htrace_htrace-core4-4.1.0-incubating.jar
22/06/11 18:00:17 INFO Executor: Adding file:/tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.htrace_htrace-core4-4.1.0-incubating.jar to class loader
22/06/11 18:00:17 INFO Executor: Fetching spark://d86e382532b9:41901/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: Fetching spark://d86e382532b9:41901/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp1953134248093318431.tmp
22/06/11 18:00:17 INFO Utils: /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp1953134248093318431.tmp has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar
22/06/11 18:00:17 INFO Executor: Adding file:/tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar to class loader
22/06/11 18:00:17 INFO Executor: Fetching spark://d86e382532b9:41901/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: Fetching spark://d86e382532b9:41901/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp7404257981703444271.tmp
22/06/11 18:00:17 INFO Utils: /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp7404257981703444271.tmp has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.spark-project.spark_unused-1.0.0.jar
22/06/11 18:00:17 INFO Executor: Adding file:/tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/org.spark-project.spark_unused-1.0.0.jar to class loader
22/06/11 18:00:17 INFO Executor: Fetching spark://d86e382532b9:41901/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654970416173
22/06/11 18:00:17 INFO Utils: Fetching spark://d86e382532b9:41901/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp1085107612984493171.tmp
22/06/11 18:00:17 INFO Utils: /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/fetchFileTemp1085107612984493171.tmp has been previously copied to /tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/com.google.code.findbugs_jsr305-3.0.0.jar
22/06/11 18:00:17 INFO Executor: Adding file:/tmp/spark-e81428b8-202f-420d-9b02-a4bef2006a6b/userFiles-d00112c4-b1fc-453f-b525-a6d8025e0670/com.google.code.findbugs_jsr305-3.0.0.jar to class loader
22/06/11 18:00:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44041.
22/06/11 18:00:17 INFO NettyBlockTransferService: Server created on d86e382532b9:44041
22/06/11 18:00:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/11 18:00:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d86e382532b9, 44041, None)
22/06/11 18:00:17 INFO BlockManagerMasterEndpoint: Registering block manager d86e382532b9:44041 with 366.3 MiB RAM, BlockManagerId(driver, d86e382532b9, 44041, None)
22/06/11 18:00:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d86e382532b9, 44041, None)
22/06/11 18:00:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d86e382532b9, 44041, None)
22/06/11 18:00:17 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/06/11 18:00:17 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
Traceback (most recent call last):
  File "/home/workspace/sparkpykafkajoin.py", line 55, in <module>
    redisServerRawStreamingDF = spark\
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming.py", line 454, in load
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o32.load.
: java.lang.NoClassDefFoundError: scala/$less$colon$less
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.org$apache$spark$sql$kafka010$KafkaSourceProvider$$validateStreamOptions(KafkaSourceProvider.scala:338)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.sourceSchema(KafkaSourceProvider.scala:71)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceSchema(DataSource.scala:236)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo$lzycompute(DataSource.scala:118)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo(DataSource.scala:118)
	at org.apache.spark.sql.execution.streaming.StreamingRelation$.apply(StreamingRelation.scala:34)
	at org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:167)
	at org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:143)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: scala.$less$colon$less
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more

:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.13 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-c8372f93-5393-4456-94b8-f3a07d5ead2f;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.13;3.2.1 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.2.1 in central
	found org.apache.kafka#kafka-clients;2.8.0 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.8.4 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.apache.hadoop#hadoop-client-runtime;3.3.1 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.hadoop#hadoop-client-api;3.3.1 in central
	found org.apache.htrace#htrace-core4;4.1.0-incubating in central
	found commons-logging#commons-logging;1.1.3 in central
	found com.google.code.findbugs#jsr305;3.0.0 in central
	found org.scala-lang.modules#scala-parallel-collections_2.13;1.0.3 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 509ms :: artifacts dl 69ms
	:: modules in use:
	com.google.code.findbugs#jsr305;3.0.0 from central in [default]
	commons-logging#commons-logging;1.1.3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.hadoop#hadoop-client-api;3.3.1 from central in [default]
	org.apache.hadoop#hadoop-client-runtime;3.3.1 from central in [default]
	org.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]
	org.apache.kafka#kafka-clients;2.8.0 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.13;3.2.1 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.2.1 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.scala-lang.modules#scala-parallel-collections_2.13;1.0.3 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.8.4 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   14  |   0   |   0   |   0   ||   14  |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-c8372f93-5393-4456-94b8-f3a07d5ead2f
	confs: [default]
	0 artifacts copied, 14 already retrieved (0kB/12ms)
22/06/11 18:01:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/11 18:01:51 INFO SparkContext: Running Spark version 3.2.1
22/06/11 18:01:51 INFO ResourceUtils: ==============================================================
22/06/11 18:01:51 INFO ResourceUtils: No custom resources configured for spark.driver.
22/06/11 18:01:51 INFO ResourceUtils: ==============================================================
22/06/11 18:01:51 INFO SparkContext: Submitted application: Evaluate-Human-Balance
22/06/11 18:01:51 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/06/11 18:01:51 INFO ResourceProfile: Limiting resource is cpu
22/06/11 18:01:51 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/06/11 18:01:51 INFO SecurityManager: Changing view acls to: spark
22/06/11 18:01:51 INFO SecurityManager: Changing modify acls to: spark
22/06/11 18:01:51 INFO SecurityManager: Changing view acls groups to: 
22/06/11 18:01:51 INFO SecurityManager: Changing modify acls groups to: 
22/06/11 18:01:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
22/06/11 18:01:51 INFO Utils: Successfully started service 'sparkDriver' on port 34609.
22/06/11 18:01:51 INFO SparkEnv: Registering MapOutputTracker
22/06/11 18:01:51 INFO SparkEnv: Registering BlockManagerMaster
22/06/11 18:01:51 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/11 18:01:51 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/11 18:01:51 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/06/11 18:01:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0b422c78-793c-45c7-a361-c34663f09a50
22/06/11 18:01:51 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/06/11 18:01:51 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/11 18:01:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/11 18:01:51 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://d86e382532b9:4040
22/06/11 18:01:51 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar at spark://d86e382532b9:34609/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar at spark://d86e382532b9:34609/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar at spark://d86e382532b9:34609/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar at spark://d86e382532b9:34609/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://d86e382532b9:34609/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://d86e382532b9:34609/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://d86e382532b9:34609/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar at spark://d86e382532b9:34609/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://d86e382532b9:34609/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar at spark://d86e382532b9:34609/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://d86e382532b9:34609/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar at spark://d86e382532b9:34609/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar at spark://d86e382532b9:34609/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://d86e382532b9:34609/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar
22/06/11 18:01:51 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar
22/06/11 18:01:51 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar at file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar
22/06/11 18:01:51 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.kafka_kafka-clients-2.8.0.jar
22/06/11 18:01:51 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/com.google.code.findbugs_jsr305-3.0.0.jar
22/06/11 18:01:51 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 18:01:51 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.spark-project.spark_unused-1.0.0.jar
22/06/11 18:01:51 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar
22/06/11 18:01:51 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.lz4_lz4-java-1.7.1.jar
22/06/11 18:01:51 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar at file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.xerial.snappy_snappy-java-1.1.8.4.jar
22/06/11 18:01:51 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 18:01:51 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.hadoop_hadoop-client-api-3.3.1.jar
22/06/11 18:01:51 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.htrace_htrace-core4-4.1.0-incubating.jar
22/06/11 18:01:51 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/commons-logging_commons-logging-1.1.3.jar
22/06/11 18:01:51 INFO Executor: Starting executor ID driver on host d86e382532b9
22/06/11 18:01:51 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: /opt/bitnami/spark/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/commons-logging_commons-logging-1.1.3.jar
22/06/11 18:01:51 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.0.jar has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.kafka_kafka-clients-2.8.0.jar
22/06/11 18:01:51 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar
22/06/11 18:01:51 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.hadoop_hadoop-client-api-3.3.1.jar
22/06/11 18:01:51 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar
22/06/11 18:01:51 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: /opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/com.google.code.findbugs_jsr305-3.0.0.jar
22/06/11 18:01:51 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar
22/06/11 18:01:51 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.htrace_htrace-core4-4.1.0-incubating.jar
22/06/11 18:01:51 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.xerial.snappy_snappy-java-1.1.8.4.jar
22/06/11 18:01:51 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 18:01:51 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.spark-project.spark_unused-1.0.0.jar
22/06/11 18:01:51 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 18:01:51 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970511261
22/06/11 18:01:51 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.lz4_lz4-java-1.7.1.jar
22/06/11 18:01:51 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654970511261
22/06/11 18:01:52 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar
22/06/11 18:01:52 INFO Executor: Fetching spark://d86e382532b9:34609/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970511261
22/06/11 18:01:52 INFO TransportClientFactory: Successfully created connection to d86e382532b9/172.22.0.4:34609 after 16 ms (0 ms spent in bootstraps)
22/06/11 18:01:52 INFO Utils: Fetching spark://d86e382532b9:34609/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp373289752745939052.tmp
22/06/11 18:01:52 INFO Utils: /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp373289752745939052.tmp has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.spark-project.spark_unused-1.0.0.jar
22/06/11 18:01:52 INFO Executor: Adding file:/tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.spark-project.spark_unused-1.0.0.jar to class loader
22/06/11 18:01:52 INFO Executor: Fetching spark://d86e382532b9:34609/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1654970511261
22/06/11 18:01:52 INFO Utils: Fetching spark://d86e382532b9:34609/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp6228175291182914058.tmp
22/06/11 18:01:52 INFO Utils: /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp6228175291182914058.tmp has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/com.google.code.findbugs_jsr305-3.0.0.jar
22/06/11 18:01:52 INFO Executor: Adding file:/tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/com.google.code.findbugs_jsr305-3.0.0.jar to class loader
22/06/11 18:01:52 INFO Executor: Fetching spark://d86e382532b9:34609/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar with timestamp 1654970511261
22/06/11 18:01:52 INFO Utils: Fetching spark://d86e382532b9:34609/jars/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp4478174335424803503.tmp
22/06/11 18:01:52 INFO Utils: /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp4478174335424803503.tmp has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar
22/06/11 18:01:52 INFO Executor: Adding file:/tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.scala-lang.modules_scala-parallel-collections_2.13-1.0.3.jar to class loader
22/06/11 18:01:52 INFO Executor: Fetching spark://d86e382532b9:34609/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970511261
22/06/11 18:01:52 INFO Utils: Fetching spark://d86e382532b9:34609/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp7212273301193143745.tmp
22/06/11 18:01:52 INFO Utils: /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp7212273301193143745.tmp has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 18:01:52 INFO Executor: Adding file:/tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.slf4j_slf4j-api-1.7.30.jar to class loader
22/06/11 18:01:52 INFO Executor: Fetching spark://d86e382532b9:34609/jars/org.apache.kafka_kafka-clients-2.8.0.jar with timestamp 1654970511261
22/06/11 18:01:52 INFO Utils: Fetching spark://d86e382532b9:34609/jars/org.apache.kafka_kafka-clients-2.8.0.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp6131416034813611263.tmp
22/06/11 18:01:52 INFO Utils: /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp6131416034813611263.tmp has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.kafka_kafka-clients-2.8.0.jar
22/06/11 18:01:52 INFO Executor: Adding file:/tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.kafka_kafka-clients-2.8.0.jar to class loader
22/06/11 18:01:52 INFO Executor: Fetching spark://d86e382532b9:34609/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar with timestamp 1654970511261
22/06/11 18:01:52 INFO Utils: Fetching spark://d86e382532b9:34609/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp3079793533930990433.tmp
22/06/11 18:01:52 INFO Utils: /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp3079793533930990433.tmp has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.hadoop_hadoop-client-api-3.3.1.jar
22/06/11 18:01:52 INFO Executor: Adding file:/tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.hadoop_hadoop-client-api-3.3.1.jar to class loader
22/06/11 18:01:52 INFO Executor: Fetching spark://d86e382532b9:34609/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1654970511261
22/06/11 18:01:52 INFO Utils: Fetching spark://d86e382532b9:34609/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp4190918235478834499.tmp
22/06/11 18:01:52 INFO Utils: /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp4190918235478834499.tmp has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.xerial.snappy_snappy-java-1.1.8.4.jar
22/06/11 18:01:52 INFO Executor: Adding file:/tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.xerial.snappy_snappy-java-1.1.8.4.jar to class loader
22/06/11 18:01:52 INFO Executor: Fetching spark://d86e382532b9:34609/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970511261
22/06/11 18:01:52 INFO Utils: Fetching spark://d86e382532b9:34609/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp1106905608911310357.tmp
22/06/11 18:01:52 INFO Utils: /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp1106905608911310357.tmp has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar
22/06/11 18:01:52 INFO Executor: Adding file:/tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.spark_spark-token-provider-kafka-0-10_2.13-3.2.1.jar to class loader
22/06/11 18:01:52 INFO Executor: Fetching spark://d86e382532b9:34609/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970511261
22/06/11 18:01:52 INFO Utils: Fetching spark://d86e382532b9:34609/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp1071899403277505924.tmp
22/06/11 18:01:52 INFO Utils: /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp1071899403277505924.tmp has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.lz4_lz4-java-1.7.1.jar
22/06/11 18:01:52 INFO Executor: Adding file:/tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.lz4_lz4-java-1.7.1.jar to class loader
22/06/11 18:01:52 INFO Executor: Fetching spark://d86e382532b9:34609/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar with timestamp 1654970511261
22/06/11 18:01:52 INFO Utils: Fetching spark://d86e382532b9:34609/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp5900180707020736810.tmp
22/06/11 18:01:52 INFO Utils: /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp5900180707020736810.tmp has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar
22/06/11 18:01:52 INFO Executor: Adding file:/tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar to class loader
22/06/11 18:01:52 INFO Executor: Fetching spark://d86e382532b9:34609/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1654970511261
22/06/11 18:01:52 INFO Utils: Fetching spark://d86e382532b9:34609/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp776105222451808408.tmp
22/06/11 18:01:52 INFO Utils: /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp776105222451808408.tmp has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/commons-logging_commons-logging-1.1.3.jar
22/06/11 18:01:52 INFO Executor: Adding file:/tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/commons-logging_commons-logging-1.1.3.jar to class loader
22/06/11 18:01:52 INFO Executor: Fetching spark://d86e382532b9:34609/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar with timestamp 1654970511261
22/06/11 18:01:52 INFO Utils: Fetching spark://d86e382532b9:34609/jars/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp3762269297304589428.tmp
22/06/11 18:01:52 INFO Utils: /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp3762269297304589428.tmp has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar
22/06/11 18:01:52 INFO Executor: Adding file:/tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.spark_spark-sql-kafka-0-10_2.13-3.2.1.jar to class loader
22/06/11 18:01:52 INFO Executor: Fetching spark://d86e382532b9:34609/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar with timestamp 1654970511261
22/06/11 18:01:52 INFO Utils: Fetching spark://d86e382532b9:34609/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp890231363418860054.tmp
22/06/11 18:01:52 INFO Utils: /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp890231363418860054.tmp has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.htrace_htrace-core4-4.1.0-incubating.jar
22/06/11 18:01:52 INFO Executor: Adding file:/tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.htrace_htrace-core4-4.1.0-incubating.jar to class loader
22/06/11 18:01:52 INFO Executor: Fetching spark://d86e382532b9:34609/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970511261
22/06/11 18:01:52 INFO Utils: Fetching spark://d86e382532b9:34609/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp6083421778464859272.tmp
22/06/11 18:01:52 INFO Utils: /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/fetchFileTemp6083421778464859272.tmp has been previously copied to /tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 18:01:52 INFO Executor: Adding file:/tmp/spark-91d858ed-e1ca-4526-8f1b-86e145e0bda0/userFiles-a959c259-0d4b-4d48-b9f8-f61fbc60dcd2/org.apache.commons_commons-pool2-2.6.2.jar to class loader
22/06/11 18:01:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36323.
22/06/11 18:01:52 INFO NettyBlockTransferService: Server created on d86e382532b9:36323
22/06/11 18:01:52 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/11 18:01:52 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d86e382532b9, 36323, None)
22/06/11 18:01:52 INFO BlockManagerMasterEndpoint: Registering block manager d86e382532b9:36323 with 366.3 MiB RAM, BlockManagerId(driver, d86e382532b9, 36323, None)
22/06/11 18:01:52 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d86e382532b9, 36323, None)
22/06/11 18:01:52 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d86e382532b9, 36323, None)
22/06/11 18:01:52 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/06/11 18:01:52 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
Traceback (most recent call last):
  File "/home/workspace/sparkpykafkajoin.py", line 55, in <module>
    redisServerRawStreamingDF = spark                          \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming.py", line 454, in load
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o32.load.
: java.lang.NoClassDefFoundError: scala/$less$colon$less
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.org$apache$spark$sql$kafka010$KafkaSourceProvider$$validateStreamOptions(KafkaSourceProvider.scala:338)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.sourceSchema(KafkaSourceProvider.scala:71)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceSchema(DataSource.scala:236)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo$lzycompute(DataSource.scala:118)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo(DataSource.scala:118)
	at org.apache.spark.sql.execution.streaming.StreamingRelation$.apply(StreamingRelation.scala:34)
	at org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:167)
	at org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:143)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: scala.$less$colon$less
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more

:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-6065f8a5-1790-4a90-9adb-77dfcad4985a;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.1 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.1 in central
	found org.apache.kafka#kafka-clients;2.6.0 in central
	found com.github.luben#zstd-jni;1.4.8-1 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.8.2 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.1.1/spark-sql-kafka-0-10_2.12-3.1.1.jar ...
	[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.1!spark-sql-kafka-0-10_2.12.jar (201ms)
downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.1.1/spark-token-provider-kafka-0-10_2.12-3.1.1.jar ...
	[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.1!spark-token-provider-kafka-0-10_2.12.jar (90ms)
downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/2.6.0/kafka-clients-2.6.0.jar ...
	[SUCCESSFUL ] org.apache.kafka#kafka-clients;2.6.0!kafka-clients.jar (336ms)
downloading https://repo1.maven.org/maven2/com/github/luben/zstd-jni/1.4.8-1/zstd-jni-1.4.8-1.jar ...
	[SUCCESSFUL ] com.github.luben#zstd-jni;1.4.8-1!zstd-jni.jar (433ms)
downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar ...
	[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.8.2!snappy-java.jar(bundle) (183ms)
:: resolution report :: resolve 5218ms :: artifacts dl 1305ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.8-1 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.6.0 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.1 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.1 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.8.2 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   5   |   5   |   0   ||   9   |   5   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-6065f8a5-1790-4a90-9adb-77dfcad4985a
	confs: [default]
	5 artifacts copied, 4 already retrieved (12279kB/191ms)
22/06/11 18:04:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/11 18:04:04 INFO SparkContext: Running Spark version 3.2.1
22/06/11 18:04:04 INFO ResourceUtils: ==============================================================
22/06/11 18:04:04 INFO ResourceUtils: No custom resources configured for spark.driver.
22/06/11 18:04:04 INFO ResourceUtils: ==============================================================
22/06/11 18:04:04 INFO SparkContext: Submitted application: Evaluate-Human-Balance
22/06/11 18:04:04 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/06/11 18:04:04 INFO ResourceProfile: Limiting resource is cpu
22/06/11 18:04:04 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/06/11 18:04:04 INFO SecurityManager: Changing view acls to: spark
22/06/11 18:04:04 INFO SecurityManager: Changing modify acls to: spark
22/06/11 18:04:04 INFO SecurityManager: Changing view acls groups to: 
22/06/11 18:04:04 INFO SecurityManager: Changing modify acls groups to: 
22/06/11 18:04:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
22/06/11 18:04:04 INFO Utils: Successfully started service 'sparkDriver' on port 41279.
22/06/11 18:04:04 INFO SparkEnv: Registering MapOutputTracker
22/06/11 18:04:04 INFO SparkEnv: Registering BlockManagerMaster
22/06/11 18:04:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/11 18:04:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/11 18:04:04 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/06/11 18:04:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f6ceb23c-04bd-43e1-88a4-a614b951bd41
22/06/11 18:04:04 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/06/11 18:04:04 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/11 18:04:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/11 18:04:04 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://d86e382532b9:4040
22/06/11 18:04:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar at spark://d86e382532b9:41279/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar at spark://d86e382532b9:41279/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar at spark://d86e382532b9:41279/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://d86e382532b9:41279/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://d86e382532b9:41279/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar at spark://d86e382532b9:41279/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://d86e382532b9:41279/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar at spark://d86e382532b9:41279/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://d86e382532b9:41279/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:04:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:04:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.apache.kafka_kafka-clients-2.6.0.jar
22/06/11 18:04:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 18:04:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.spark-project.spark_unused-1.0.0.jar
22/06/11 18:04:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar at file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/com.github.luben_zstd-jni-1.4.8-1.jar
22/06/11 18:04:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.lz4_lz4-java-1.7.1.jar
22/06/11 18:04:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.xerial.snappy_snappy-java-1.1.8.2.jar
22/06/11 18:04:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970644375
22/06/11 18:04:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 18:04:05 INFO Executor: Starting executor ID driver on host d86e382532b9
22/06/11 18:04:05 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.xerial.snappy_snappy-java-1.1.8.2.jar
22/06/11 18:04:05 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:04:05 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/com.github.luben_zstd-jni-1.4.8-1.jar
22/06/11 18:04:05 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:04:05 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 18:04:05 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.spark-project.spark_unused-1.0.0.jar
22/06/11 18:04:05 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.lz4_lz4-java-1.7.1.jar
22/06/11 18:04:05 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.apache.kafka_kafka-clients-2.6.0.jar
22/06/11 18:04:05 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 18:04:05 INFO Executor: Fetching spark://d86e382532b9:41279/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO TransportClientFactory: Successfully created connection to d86e382532b9/172.22.0.4:41279 after 18 ms (0 ms spent in bootstraps)
22/06/11 18:04:05 INFO Utils: Fetching spark://d86e382532b9:41279/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp9110936410362912817.tmp
22/06/11 18:04:05 INFO Utils: /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp9110936410362912817.tmp has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:04:05 INFO Executor: Adding file:/tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar to class loader
22/06/11 18:04:05 INFO Executor: Fetching spark://d86e382532b9:41279/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: Fetching spark://d86e382532b9:41279/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp5416039667871526558.tmp
22/06/11 18:04:05 INFO Utils: /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp5416039667871526558.tmp has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:04:05 INFO Executor: Adding file:/tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar to class loader
22/06/11 18:04:05 INFO Executor: Fetching spark://d86e382532b9:41279/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: Fetching spark://d86e382532b9:41279/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp303934683367651539.tmp
22/06/11 18:04:05 INFO Utils: /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp303934683367651539.tmp has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 18:04:05 INFO Executor: Adding file:/tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.slf4j_slf4j-api-1.7.30.jar to class loader
22/06/11 18:04:05 INFO Executor: Fetching spark://d86e382532b9:41279/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: Fetching spark://d86e382532b9:41279/jars/org.apache.kafka_kafka-clients-2.6.0.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp1873142166684735579.tmp
22/06/11 18:04:05 INFO Utils: /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp1873142166684735579.tmp has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.apache.kafka_kafka-clients-2.6.0.jar
22/06/11 18:04:05 INFO Executor: Adding file:/tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.apache.kafka_kafka-clients-2.6.0.jar to class loader
22/06/11 18:04:05 INFO Executor: Fetching spark://d86e382532b9:41279/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: Fetching spark://d86e382532b9:41279/jars/com.github.luben_zstd-jni-1.4.8-1.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp4862965387409966157.tmp
22/06/11 18:04:05 INFO Utils: /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp4862965387409966157.tmp has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/com.github.luben_zstd-jni-1.4.8-1.jar
22/06/11 18:04:05 INFO Executor: Adding file:/tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/com.github.luben_zstd-jni-1.4.8-1.jar to class loader
22/06/11 18:04:05 INFO Executor: Fetching spark://d86e382532b9:41279/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: Fetching spark://d86e382532b9:41279/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp5450157784949386010.tmp
22/06/11 18:04:05 INFO Utils: /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp5450157784949386010.tmp has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.lz4_lz4-java-1.7.1.jar
22/06/11 18:04:05 INFO Executor: Adding file:/tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.lz4_lz4-java-1.7.1.jar to class loader
22/06/11 18:04:05 INFO Executor: Fetching spark://d86e382532b9:41279/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: Fetching spark://d86e382532b9:41279/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp2901738483335178824.tmp
22/06/11 18:04:05 INFO Utils: /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp2901738483335178824.tmp has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.spark-project.spark_unused-1.0.0.jar
22/06/11 18:04:05 INFO Executor: Adding file:/tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.spark-project.spark_unused-1.0.0.jar to class loader
22/06/11 18:04:05 INFO Executor: Fetching spark://d86e382532b9:41279/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: Fetching spark://d86e382532b9:41279/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp7481658316886674551.tmp
22/06/11 18:04:05 INFO Utils: /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp7481658316886674551.tmp has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 18:04:05 INFO Executor: Adding file:/tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.apache.commons_commons-pool2-2.6.2.jar to class loader
22/06/11 18:04:05 INFO Executor: Fetching spark://d86e382532b9:41279/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1654970644375
22/06/11 18:04:05 INFO Utils: Fetching spark://d86e382532b9:41279/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp1532658750275484513.tmp
22/06/11 18:04:05 INFO Utils: /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/fetchFileTemp1532658750275484513.tmp has been previously copied to /tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.xerial.snappy_snappy-java-1.1.8.2.jar
22/06/11 18:04:05 INFO Executor: Adding file:/tmp/spark-ec6b0956-13e5-4451-b8a7-414d7269c50f/userFiles-ee5c208e-791e-43b9-b4a3-ff564a916877/org.xerial.snappy_snappy-java-1.1.8.2.jar to class loader
22/06/11 18:04:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45991.
22/06/11 18:04:05 INFO NettyBlockTransferService: Server created on d86e382532b9:45991
22/06/11 18:04:05 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/11 18:04:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d86e382532b9, 45991, None)
22/06/11 18:04:05 INFO BlockManagerMasterEndpoint: Registering block manager d86e382532b9:45991 with 366.3 MiB RAM, BlockManagerId(driver, d86e382532b9, 45991, None)
22/06/11 18:04:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d86e382532b9, 45991, None)
22/06/11 18:04:05 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d86e382532b9, 45991, None)
22/06/11 18:04:05 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/06/11 18:04:05 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
22/06/11 18:04:08 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
^C^C^C^C22/06/11 18:06:34 ERROR Utils: Aborting task
java.lang.IllegalStateException: Error committing version 1 into HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/kafkacheckpoint/state/0/161/left-keyWithIndexToValue]
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager$StateStoreHandler.commit(SymmetricHashJoinStateManager.scala:349)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager.commit(SymmetricHashJoinStateManager.scala:303)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec$OneSideHashJoiner.commitStateAndGetMetrics(StreamingSymmetricHashJoinExec.scala:625)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.$anonfun$processPartitions$23(StreamingSymmetricHashJoinExec.scala:420)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:605)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:142)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:142)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.timeTakenMs(StreamingSymmetricHashJoinExec.scala:127)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.onOutputCompletion$1(StreamingSymmetricHashJoinExec.scala:419)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.$anonfun$processPartitions$25(StreamingSymmetricHashJoinExec.scala:439)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:47)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:36)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:412)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:457)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:358)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: ExitCodeException exitCode=130: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1008)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:324)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:294)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:439)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)
	at org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)
	at org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)
	at org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:360)
	at org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400)
	at org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.create(FileContext.java:703)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:327)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:333)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:141)
	... 26 more
22/06/11 18:06:36 ERROR Utils: Aborting task
java.lang.IllegalStateException: Error committing version 1 into HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/kafkacheckpoint/state/0/167/left-keyToNumValues]
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager$StateStoreHandler.commit(SymmetricHashJoinStateManager.scala:349)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager.commit(SymmetricHashJoinStateManager.scala:302)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec$OneSideHashJoiner.commitStateAndGetMetrics(StreamingSymmetricHashJoinExec.scala:625)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.$anonfun$processPartitions$23(StreamingSymmetricHashJoinExec.scala:420)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:605)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:142)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:142)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.timeTakenMs(StreamingSymmetricHashJoinExec.scala:127)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.onOutputCompletion$1(StreamingSymmetricHashJoinExec.scala:419)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.$anonfun$processPartitions$25(StreamingSymmetricHashJoinExec.scala:439)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:47)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:36)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:412)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:457)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:358)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: ExitCodeException exitCode=130: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1008)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:324)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:294)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:439)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)
	at org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)
	at org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)
	at org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:360)
	at org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400)
	at org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.create(FileContext.java:703)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:327)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:333)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:141)
	... 26 more
22/06/11 18:06:35 ERROR Utils: Aborting task
java.lang.IllegalStateException: Error committing version 1 into HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/kafkacheckpoint/state/0/163/right-keyToNumValues]
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager$StateStoreHandler.commit(SymmetricHashJoinStateManager.scala:349)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager.commit(SymmetricHashJoinStateManager.scala:302)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec$OneSideHashJoiner.commitStateAndGetMetrics(StreamingSymmetricHashJoinExec.scala:625)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.$anonfun$processPartitions$23(StreamingSymmetricHashJoinExec.scala:421)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:605)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:142)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:142)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.timeTakenMs(StreamingSymmetricHashJoinExec.scala:127)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.onOutputCompletion$1(StreamingSymmetricHashJoinExec.scala:419)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.$anonfun$processPartitions$25(StreamingSymmetricHashJoinExec.scala:439)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:47)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:36)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:412)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:457)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:358)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: ExitCodeException exitCode=130: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1008)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:324)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:294)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:439)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)
	at org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)
	at org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)
	at org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:353)
	at org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400)
	at org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.create(FileContext.java:703)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:327)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:333)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:141)
	... 26 more

22/06/11 18:06:37 ERROR DataWritingSparkTask: Aborting commit for partition 161 (task 178, attempt 0, stage 2.0)
22/06/11 18:06:37 ERROR DataWritingSparkTask: Aborting commit for partition 167 (task 181, attempt 0, stage 2.0)
22/06/11 18:06:37 ERROR DataWritingSparkTask: Aborting commit for partition 163 (task 179, attempt 0, stage 2.0)
22/06/11 18:06:37 ERROR DataWritingSparkTask: Aborted commit for partition 161 (task 178, attempt 0, stage 2.0)
22/06/11 18:06:37 ERROR DataWritingSparkTask: Aborted commit for partition 163 (task 179, attempt 0, stage 2.0)
22/06/11 18:06:37 ERROR DataWritingSparkTask: Aborted commit for partition 167 (task 181, attempt 0, stage 2.0)

22/06/11 18:06:38 ERROR Executor: Exception in task 163.0 in stage 2.0 (TID 179)
java.lang.IllegalStateException: Error committing version 1 into HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/kafkacheckpoint/state/0/163/right-keyToNumValues]
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager$StateStoreHandler.commit(SymmetricHashJoinStateManager.scala:349)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager.commit(SymmetricHashJoinStateManager.scala:302)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec$OneSideHashJoiner.commitStateAndGetMetrics(StreamingSymmetricHashJoinExec.scala:625)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.$anonfun$processPartitions$23(StreamingSymmetricHashJoinExec.scala:421)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:605)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:142)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:142)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.timeTakenMs(StreamingSymmetricHashJoinExec.scala:127)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.onOutputCompletion$1(StreamingSymmetricHashJoinExec.scala:419)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.$anonfun$processPartitions$25(StreamingSymmetricHashJoinExec.scala:439)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:47)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:36)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:412)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:457)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:358)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: ExitCodeException exitCode=130: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1008)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:324)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:294)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:439)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)
	at org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)
	at org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)
	at org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:353)
	at org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400)
	at org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.create(FileContext.java:703)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:327)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:333)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:141)
	... 26 more
ERROR:root:KeyboardInterrupt while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
RuntimeError: reentrant call inside <_io.BufferedReader name=3>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/opt/bitnami/python/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 292, in signal_handler
    self.cancelAllJobs()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 1195, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1320, in __call__
    answer = self.gateway_client.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1055, in send_command
    logging.exception(
  File "/opt/bitnami/python/lib/python3.8/logging/__init__.py", line 2057, in exception
    error(msg, *args, exc_info=exc_info, **kwargs)
  File "/opt/bitnami/python/lib/python3.8/logging/__init__.py", line 2048, in error
    basicConfig()
  File "/opt/bitnami/python/lib/python3.8/logging/__init__.py", line 1991, in basicConfig
    h = StreamHandler(stream)
  File "/opt/bitnami/python/lib/python3.8/logging/__init__.py", line 1057, in __init__
    Handler.__init__(self)
  File "/opt/bitnami/python/lib/python3.8/logging/__init__.py", line 868, in __init__
    self._name = None
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 292, in signal_handler
    self.cancelAllJobs()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 1195, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1320, in __call__
    answer = self.gateway_client.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1036, in send_command
    connection = self._get_connection()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 281, in _get_connection
    connection = self._create_new_connection()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 284, in _create_new_connection
    def _create_new_connection(self):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 292, in signal_handler
    self.cancelAllJobs()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 1195, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1377, in __getattr__
    def __getattr__(self, name):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 293, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
22/06/11 18:06:42 WARN Shell: Interrupted while joining on: Thread[Thread-8155,5,]
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1257)
	at java.lang.Thread.join(Thread.java:1331)
	at org.apache.hadoop.util.Shell.joinThread(Shell.java:1043)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1003)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)
	at org.apache.hadoop.fs.FileUtil.readLink(FileUtil.java:211)
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileLinkStatusInternal(RawLocalFileSystem.java:1113)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1102)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatus(RawLocalFileSystem.java:1073)
	at org.apache.hadoop.fs.FileSystem.rename(FileSystem.java:1574)
	at org.apache.hadoop.fs.DelegateToFileSystem.renameInternal(DelegateToFileSystem.java:206)
	at org.apache.hadoop.fs.AbstractFileSystem.renameInternal(AbstractFileSystem.java:790)
	at org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:720)
	at org.apache.hadoop.fs.ChecksumFs.renameInternal(ChecksumFs.java:496)
	at org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:720)
	at org.apache.hadoop.fs.FileContext.rename(FileContext.java:1036)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.renameTempFile(CheckpointFileManager.scala:346)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.close(CheckpointFileManager.scala:154)
	at net.jpountz.lz4.LZ4BlockOutputStream.close(LZ4BlockOutputStream.java:196)
	at java.io.FilterOutputStream.close(FilterOutputStream.java:159)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.finalizeDeltaFile(HDFSBackedStateStoreProvider.scala:450)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$commitUpdates(HDFSBackedStateStoreProvider.scala:320)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:141)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager$StateStoreHandler.commit(SymmetricHashJoinStateManager.scala:349)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager.commit(SymmetricHashJoinStateManager.scala:302)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec$OneSideHashJoiner.commitStateAndGetMetrics(StreamingSymmetricHashJoinExec.scala:625)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.$anonfun$processPartitions$23(StreamingSymmetricHashJoinExec.scala:421)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:605)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:142)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:142)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.timeTakenMs(StreamingSymmetricHashJoinExec.scala:127)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.onOutputCompletion$1(StreamingSymmetricHashJoinExec.scala:419)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.$anonfun$processPartitions$25(StreamingSymmetricHashJoinExec.scala:439)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:47)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:36)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:412)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:457)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:358)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
22/06/11 18:06:41 WARN Shell: Interrupted while joining on: Thread[Thread-8151,5,]
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1257)
	at java.lang.Thread.join(Thread.java:1331)
	at org.apache.hadoop.util.Shell.joinThread(Shell.java:1043)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1003)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:324)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:294)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:439)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)
	at org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)
	at org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)
	at org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:360)
	at org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400)
	at org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.create(FileContext.java:703)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:327)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:333)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:141)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager$StateStoreHandler.commit(SymmetricHashJoinStateManager.scala:349)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager.commit(SymmetricHashJoinStateManager.scala:303)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec$OneSideHashJoiner.commitStateAndGetMetrics(StreamingSymmetricHashJoinExec.scala:625)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.$anonfun$processPartitions$23(StreamingSymmetricHashJoinExec.scala:420)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:605)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:142)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:142)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.timeTakenMs(StreamingSymmetricHashJoinExec.scala:127)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.onOutputCompletion$1(StreamingSymmetricHashJoinExec.scala:419)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.$anonfun$processPartitions$25(StreamingSymmetricHashJoinExec.scala:439)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:47)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:36)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:412)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:457)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:358)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
RuntimeError: reentrant call inside <_io.BufferedReader name=3>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
22/06/11 18:06:41 WARN Shell: Interrupted while joining on: Thread[Thread-8154,5,]
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1257)
	at java.lang.Thread.join(Thread.java:1331)
	at org.apache.hadoop.util.Shell.joinThread(Shell.java:1043)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1003)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:324)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:294)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:439)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)
	at org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)
	at org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)
	at org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:360)
	at org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400)
	at org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.create(FileContext.java:703)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:327)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:333)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.abort(HDFSBackedStateStoreProvider.scala:158)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager$StateStoreHandler.abortIfNeeded(SymmetricHashJoinStateManager.scala:356)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager.abortIfNeeded(SymmetricHashJoinStateManager.scala:309)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager.$anonfun$new$2(SymmetricHashJoinStateManager.scala:340)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager.$anonfun$new$2$adapted(SymmetricHashJoinStateManager.scala:340)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:130)
	at org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:142)
	at org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:142)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:197)
	at org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:142)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:135)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
22/06/11 18:06:41 WARN Shell: Interrupted while joining on: Thread[Thread-8153,5,]
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1257)
	at java.lang.Thread.join(Thread.java:1331)
	at org.apache.hadoop.util.Shell.joinThread(Shell.java:1043)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1003)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)
	at org.apache.hadoop.fs.FileUtil.readLink(FileUtil.java:211)
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileLinkStatusInternal(RawLocalFileSystem.java:1113)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1102)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatus(RawLocalFileSystem.java:1073)
	at org.apache.hadoop.fs.FileSystem.rename(FileSystem.java:1590)
	at org.apache.hadoop.fs.DelegateToFileSystem.renameInternal(DelegateToFileSystem.java:206)
	at org.apache.hadoop.fs.AbstractFileSystem.renameInternal(AbstractFileSystem.java:790)
	at org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:720)
	at org.apache.hadoop.fs.ChecksumFs.renameInternal(ChecksumFs.java:496)
	at org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:720)
	at org.apache.hadoop.fs.FileContext.rename(FileContext.java:1036)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.renameTempFile(CheckpointFileManager.scala:346)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.close(CheckpointFileManager.scala:154)
	at net.jpountz.lz4.LZ4BlockOutputStream.close(LZ4BlockOutputStream.java:196)
	at java.io.FilterOutputStream.close(FilterOutputStream.java:159)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.finalizeDeltaFile(HDFSBackedStateStoreProvider.scala:450)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$commitUpdates(HDFSBackedStateStoreProvider.scala:320)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:141)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager$StateStoreHandler.commit(SymmetricHashJoinStateManager.scala:349)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager.commit(SymmetricHashJoinStateManager.scala:302)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec$OneSideHashJoiner.commitStateAndGetMetrics(StreamingSymmetricHashJoinExec.scala:625)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.$anonfun$processPartitions$23(StreamingSymmetricHashJoinExec.scala:421)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:605)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:142)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:142)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.timeTakenMs(StreamingSymmetricHashJoinExec.scala:127)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.onOutputCompletion$1(StreamingSymmetricHashJoinExec.scala:419)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.$anonfun$processPartitions$25(StreamingSymmetricHashJoinExec.scala:439)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:47)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:36)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:412)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:457)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:358)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
22/06/11 18:06:42 WARN Shell: Interrupted while joining on: Thread[Thread-8156,5,]
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1257)
	at java.lang.Thread.join(Thread.java:1331)
	at org.apache.hadoop.util.Shell.joinThread(Shell.java:1043)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1003)
	at org.apache.hadoop.util.Shell.run(Shell.java:901)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:324)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:294)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:439)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)
	at org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)
	at org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)
	at org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:360)
	at org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400)
	at org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.create(FileContext.java:703)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:327)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:333)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.abort(HDFSBackedStateStoreProvider.scala:158)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager$StateStoreHandler.abortIfNeeded(SymmetricHashJoinStateManager.scala:356)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager.abortIfNeeded(SymmetricHashJoinStateManager.scala:309)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager.$anonfun$new$2(SymmetricHashJoinStateManager.scala:340)
	at org.apache.spark.sql.execution.streaming.state.SymmetricHashJoinStateManager.$anonfun$new$2$adapted(SymmetricHashJoinStateManager.scala:340)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:130)
	at org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:142)
	at org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:142)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:197)
	at org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:142)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:135)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 503, in send_command
py4j.protocol.Py4JNetworkError: Error while sending or receiving

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/workspace/sparkpykafkajoin.py", line 200, in <module>
    customerRiskStreamingDF.selectExpr("to_json(struct(*)) AS value")\
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming.py", line 101, in awaitTermination
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1320, in __call__
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
  File "/opt/bitnami/python/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 292, in signal_handler
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 1195, in cancelAllJobs
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1320, in __call__
22/06/11 18:07:02 ERROR WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@13d8c9db is aborting.
22/06/11 18:07:02 ERROR WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@13d8c9db aborted.
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1055, in send_command
  File "/opt/bitnami/python/lib/python3.8/logging/__init__.py", line 2057, in exception
    error(msg, *args, exc_info=exc_info, **kwargs)
  File "/opt/bitnami/python/lib/python3.8/logging/__init__.py", line 2048, in error
    basicConfig()
  File "/opt/bitnami/python/lib/python3.8/logging/__init__.py", line 1991, in basicConfig
    h = StreamHandler(stream)
  File "/opt/bitnami/python/lib/python3.8/logging/__init__.py", line 1057, in __init__
    Handler.__init__(self)
  File "/opt/bitnami/python/lib/python3.8/logging/__init__.py", line 868, in __init__
    self._name = None
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 292, in signal_handler
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 1195, in cancelAllJobs
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1320, in __call__
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1036, in send_command
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 281, in _get_connection
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 284, in _create_new_connection
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 292, in signal_handler
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 1195, in cancelAllJobs
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1377, in __getattr__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 293, in signal_handler
KeyboardInterrupt
22/06/11 18:07:02 WARN TaskSetManager: Lost task 167.0 in stage 2.0 (TID 181) (d86e382532b9 executor driver): TaskKilled (Stage cancelled)
22/06/11 18:07:02 WARN TaskSetManager: Lost task 161.0 in stage 2.0 (TID 178) (d86e382532b9 executor driver): TaskKilled (Stage cancelled)
22/06/11 18:07:03 ERROR Utils: Aborting task
org.apache.spark.executor.CommitDeniedException: Commit denied for partition 160 (task 177, attempt 0, stage 2.0)
	at org.apache.spark.sql.errors.QueryExecutionErrors$.commitDeniedError(QueryExecutionErrors.scala:620)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:433)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:457)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:358)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
22/06/11 18:07:03 ERROR DataWritingSparkTask: Aborting commit for partition 160 (task 177, attempt 0, stage 2.0)
22/06/11 18:07:03 ERROR DataWritingSparkTask: Aborted commit for partition 160 (task 177, attempt 0, stage 2.0)
22/06/11 18:07:03 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$Lambda$4023/104265499@2056a9e9 rejected from java.util.concurrent.ThreadPoolExecutor@f1d3898[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 179]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:137)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:817)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:791)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:71)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
22/06/11 18:07:03 ERROR Utils: Aborting task
org.apache.spark.executor.CommitDeniedException: Commit denied for partition 165 (task 180, attempt 0, stage 2.0)
	at org.apache.spark.sql.errors.QueryExecutionErrors$.commitDeniedError(QueryExecutionErrors.scala:620)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:433)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:457)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:358)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
22/06/11 18:07:03 ERROR DataWritingSparkTask: Aborting commit for partition 165 (task 180, attempt 0, stage 2.0)
22/06/11 18:07:03 ERROR DataWritingSparkTask: Aborted commit for partition 165 (task 180, attempt 0, stage 2.0)
22/06/11 18:07:03 ERROR MicroBatchExecution: Query [id = 017363b8-5645-4409-b186-f7817067c1f5, runId = f9b3d360-a860-4f87-b44d-83f151e2f9f6] terminated with error
org.apache.spark.SparkException: Writing job aborted
	at org.apache.spark.sql.errors.QueryExecutionErrors$.writingJobAbortedError(QueryExecutionErrors.scala:613)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:386)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:330)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.writeWithV2(WriteToDataSourceV2Exec.scala:279)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.run(WriteToDataSourceV2Exec.scala:290)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)
	at org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:2971)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)
	at org.apache.spark.sql.Dataset.collect(Dataset.scala:2971)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:603)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:598)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:69)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:598)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:228)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:69)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:193)
	at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:187)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:303)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:286)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:209)
Caused by: org.apache.spark.SparkException: Job 0 cancelled as part of cancellation of all jobs
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:2350)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$doCancelAllJobs$2(DAGScheduler.scala:1053)
	at scala.runtime.java8.JFunction1$mcVI$sp.apply(JFunction1$mcVI$sp.java:23)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)
	at org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:1052)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2607)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:354)
	... 40 more
22/06/11 18:07:03 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@7b2bf26e rejected from java.util.concurrent.ScheduledThreadPoolExecutor@4ccedf8e[Shutting down, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 0]
22/06/11 18:07:03 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@6eee480b rejected from java.util.concurrent.ScheduledThreadPoolExecutor@4ccedf8e[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
22/06/11 18:07:03 WARN StateStore: Error managing HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/kafkacheckpoint/state/0/127/right-keyToNumValues], stopping management thread
22/06/11 18:07:03 WARN StateStore: Error running maintenance thread
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef$.forExecutor(StateStoreCoordinator.scala:84)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.coordinatorRef(StateStore.scala:648)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.verifyIfStoreInstanceActive(StateStore.scala:630)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.$anonfun$doMaintenance$2(StateStore.scala:595)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.$anonfun$doMaintenance$2$adapted(StateStore.scala:593)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.doMaintenance(StateStore.scala:593)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.$anonfun$startMaintenanceIfNeeded$1(StateStore.scala:577)
	at org.apache.spark.sql.execution.streaming.state.StateStore$MaintenanceTask$$anon$1.run(StateStore.scala:442)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:176)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
	at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:555)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:559)
	at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:74)
	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:144)
	... 21 more
:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-cee50579-53e5-4a7f-a354-e07103edc853;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.1 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.1 in central
	found org.apache.kafka#kafka-clients;2.6.0 in central
	found com.github.luben#zstd-jni;1.4.8-1 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.8.2 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 492ms :: artifacts dl 69ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.8-1 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.6.0 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.1 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.1 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.8.2 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-cee50579-53e5-4a7f-a354-e07103edc853
	confs: [default]
	0 artifacts copied, 9 already retrieved (0kB/15ms)
22/06/11 18:07:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/11 18:07:44 INFO SparkContext: Running Spark version 3.2.1
22/06/11 18:07:44 INFO ResourceUtils: ==============================================================
22/06/11 18:07:44 INFO ResourceUtils: No custom resources configured for spark.driver.
22/06/11 18:07:44 INFO ResourceUtils: ==============================================================
22/06/11 18:07:44 INFO SparkContext: Submitted application: Evaluate-Human-Balance
22/06/11 18:07:44 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/06/11 18:07:44 INFO ResourceProfile: Limiting resource is cpu
22/06/11 18:07:44 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/06/11 18:07:44 INFO SecurityManager: Changing view acls to: spark
22/06/11 18:07:44 INFO SecurityManager: Changing modify acls to: spark
22/06/11 18:07:44 INFO SecurityManager: Changing view acls groups to: 
22/06/11 18:07:44 INFO SecurityManager: Changing modify acls groups to: 
22/06/11 18:07:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
22/06/11 18:07:45 INFO Utils: Successfully started service 'sparkDriver' on port 41885.
22/06/11 18:07:45 INFO SparkEnv: Registering MapOutputTracker
22/06/11 18:07:45 INFO SparkEnv: Registering BlockManagerMaster
22/06/11 18:07:45 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/11 18:07:45 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/11 18:07:45 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/06/11 18:07:45 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8e5216fa-9d9a-4c7f-8148-aa0f4e0050fb
22/06/11 18:07:45 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/06/11 18:07:45 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/11 18:07:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/11 18:07:45 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://d86e382532b9:4040
22/06/11 18:07:45 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar at spark://d86e382532b9:41885/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar at spark://d86e382532b9:41885/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar at spark://d86e382532b9:41885/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://d86e382532b9:41885/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://d86e382532b9:41885/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar at spark://d86e382532b9:41885/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://d86e382532b9:41885/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar at spark://d86e382532b9:41885/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://d86e382532b9:41885/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:07:45 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:07:45 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.apache.kafka_kafka-clients-2.6.0.jar
22/06/11 18:07:45 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 18:07:45 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.spark-project.spark_unused-1.0.0.jar
22/06/11 18:07:45 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar at file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/com.github.luben_zstd-jni-1.4.8-1.jar
22/06/11 18:07:45 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.lz4_lz4-java-1.7.1.jar
22/06/11 18:07:45 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.xerial.snappy_snappy-java-1.1.8.2.jar
22/06/11 18:07:45 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 18:07:45 INFO Executor: Starting executor ID driver on host d86e382532b9
22/06/11 18:07:45 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.xerial.snappy_snappy-java-1.1.8.2.jar
22/06/11 18:07:45 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:07:45 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/com.github.luben_zstd-jni-1.4.8-1.jar
22/06/11 18:07:45 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:07:45 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 18:07:45 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.spark-project.spark_unused-1.0.0.jar
22/06/11 18:07:45 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.lz4_lz4-java-1.7.1.jar
22/06/11 18:07:45 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.apache.kafka_kafka-clients-2.6.0.jar
22/06/11 18:07:45 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 18:07:45 INFO Executor: Fetching spark://d86e382532b9:41885/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO TransportClientFactory: Successfully created connection to d86e382532b9/172.22.0.4:41885 after 20 ms (0 ms spent in bootstraps)
22/06/11 18:07:45 INFO Utils: Fetching spark://d86e382532b9:41885/jars/com.github.luben_zstd-jni-1.4.8-1.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp5940885937295877586.tmp
22/06/11 18:07:45 INFO Utils: /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp5940885937295877586.tmp has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/com.github.luben_zstd-jni-1.4.8-1.jar
22/06/11 18:07:45 INFO Executor: Adding file:/tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/com.github.luben_zstd-jni-1.4.8-1.jar to class loader
22/06/11 18:07:45 INFO Executor: Fetching spark://d86e382532b9:41885/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Fetching spark://d86e382532b9:41885/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp7591408254057217043.tmp
22/06/11 18:07:45 INFO Utils: /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp7591408254057217043.tmp has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 18:07:45 INFO Executor: Adding file:/tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.slf4j_slf4j-api-1.7.30.jar to class loader
22/06/11 18:07:45 INFO Executor: Fetching spark://d86e382532b9:41885/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Fetching spark://d86e382532b9:41885/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp6502309234161741121.tmp
22/06/11 18:07:45 INFO Utils: /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp6502309234161741121.tmp has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:07:45 INFO Executor: Adding file:/tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar to class loader
22/06/11 18:07:45 INFO Executor: Fetching spark://d86e382532b9:41885/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Fetching spark://d86e382532b9:41885/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp2476979798893676663.tmp
22/06/11 18:07:45 INFO Utils: /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp2476979798893676663.tmp has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.lz4_lz4-java-1.7.1.jar
22/06/11 18:07:45 INFO Executor: Adding file:/tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.lz4_lz4-java-1.7.1.jar to class loader
22/06/11 18:07:45 INFO Executor: Fetching spark://d86e382532b9:41885/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Fetching spark://d86e382532b9:41885/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp2708410811161630419.tmp
22/06/11 18:07:45 INFO Utils: /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp2708410811161630419.tmp has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:07:45 INFO Executor: Adding file:/tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar to class loader
22/06/11 18:07:45 INFO Executor: Fetching spark://d86e382532b9:41885/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Fetching spark://d86e382532b9:41885/jars/org.apache.kafka_kafka-clients-2.6.0.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp512016901010044396.tmp
22/06/11 18:07:45 INFO Utils: /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp512016901010044396.tmp has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.apache.kafka_kafka-clients-2.6.0.jar
22/06/11 18:07:45 INFO Executor: Adding file:/tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.apache.kafka_kafka-clients-2.6.0.jar to class loader
22/06/11 18:07:45 INFO Executor: Fetching spark://d86e382532b9:41885/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Fetching spark://d86e382532b9:41885/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp4526363347123263726.tmp
22/06/11 18:07:45 INFO Utils: /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp4526363347123263726.tmp has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 18:07:45 INFO Executor: Adding file:/tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.apache.commons_commons-pool2-2.6.2.jar to class loader
22/06/11 18:07:45 INFO Executor: Fetching spark://d86e382532b9:41885/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Fetching spark://d86e382532b9:41885/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp2778615685299530038.tmp
22/06/11 18:07:45 INFO Utils: /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp2778615685299530038.tmp has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.spark-project.spark_unused-1.0.0.jar
22/06/11 18:07:45 INFO Executor: Adding file:/tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.spark-project.spark_unused-1.0.0.jar to class loader
22/06/11 18:07:45 INFO Executor: Fetching spark://d86e382532b9:41885/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1654970864737
22/06/11 18:07:45 INFO Utils: Fetching spark://d86e382532b9:41885/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp7367338774940412815.tmp
22/06/11 18:07:45 INFO Utils: /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/fetchFileTemp7367338774940412815.tmp has been previously copied to /tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.xerial.snappy_snappy-java-1.1.8.2.jar
22/06/11 18:07:45 INFO Executor: Adding file:/tmp/spark-3028a501-1324-4c58-8af9-3d75ab9f8ec9/userFiles-3d9283f9-4cf6-48ec-bf78-2d270f8931a5/org.xerial.snappy_snappy-java-1.1.8.2.jar to class loader
22/06/11 18:07:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42193.
22/06/11 18:07:45 INFO NettyBlockTransferService: Server created on d86e382532b9:42193
22/06/11 18:07:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/11 18:07:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d86e382532b9, 42193, None)
22/06/11 18:07:45 INFO BlockManagerMasterEndpoint: Registering block manager d86e382532b9:42193 with 366.3 MiB RAM, BlockManagerId(driver, d86e382532b9, 42193, None)
22/06/11 18:07:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d86e382532b9, 42193, None)
22/06/11 18:07:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d86e382532b9, 42193, None)
22/06/11 18:07:46 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/06/11 18:07:46 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
22/06/11 18:07:49 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
22/06/11 18:07:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:07:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:07:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:07:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:07:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:07:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:07:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:07:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:07:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:07:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:07:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:07:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:07:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:07:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:07:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:07:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:07:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:07:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:07:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:07:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:07:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:07:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:07:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:07:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
22/06/11 18:08:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
22/06/11 18:08:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor-2, groupId=spark-kafka-source-438c1733-a9e2-4b9b-8911-5149faecfeba-670584047-executor] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
^CERROR:root:Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
RuntimeError: reentrant call inside <_io.BufferedReader name=3>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
ERROR:root:Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/opt/bitnami/python/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 292, in signal_handler
    self.cancelAllJobs()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 1195, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
    return f(*a, **kw)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o14.sc

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
Traceback (most recent call last):
  File "/home/workspace/sparkpykafkajoin.py", line 200, in <module>
    customerRiskStreamingDF.selectExpr("to_json(struct(*)) AS value")\
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming.py", line 101, in awaitTermination
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 334, in get_return_value
py4j.protocol.Py4JError: An error occurred while calling o98.awaitTermination
22/06/11 18:08:18 ERROR WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1f430cbf is aborting.
22/06/11 18:08:18 ERROR WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1f430cbf aborted.
22/06/11 18:08:18 ERROR MicroBatchExecution: Query [id = 017363b8-5645-4409-b186-f7817067c1f5, runId = 985359b7-ae37-478e-a673-d6eab1152239] terminated with error
org.apache.spark.SparkException: Writing job aborted
	at org.apache.spark.sql.errors.QueryExecutionErrors$.writingJobAbortedError(QueryExecutionErrors.scala:613)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:386)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:330)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.writeWithV2(WriteToDataSourceV2Exec.scala:279)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.run(WriteToDataSourceV2Exec.scala:290)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)
	at org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:2971)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)
	at org.apache.spark.sql.Dataset.collect(Dataset.scala:2971)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:603)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:598)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:69)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:598)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:228)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:69)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:193)
	at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:187)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:303)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:286)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:209)
Caused by: org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1(DAGScheduler.scala:1166)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1$adapted(DAGScheduler.scala:1164)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:1164)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2666)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2566)
	at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2086)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1442)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2086)
	at org.apache.spark.SparkContext.$anonfun$new$38(SparkContext.scala:667)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2019)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:354)
	... 40 more
22/06/11 18:08:18 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@4f5ddc87 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@499efdc6[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
Exception in thread "stream execution thread for [id = 017363b8-5645-4409-b186-f7817067c1f5, runId = 985359b7-ae37-478e-a673-d6eab1152239]" org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
	at org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef.deactivateInstances(StateStoreCoordinator.scala:119)
	at org.apache.spark.sql.streaming.StreamingQueryManager.notifyQueryTermination(StreamingQueryManager.scala:402)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$3(StreamExecution.scala:352)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:333)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:209)
Caused by: org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:176)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
	at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:555)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:559)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:102)
	... 8 more
:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-54434320-058a-4a51-8295-d57d116486f0;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.1 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.1 in central
	found org.apache.kafka#kafka-clients;2.6.0 in central
	found com.github.luben#zstd-jni;1.4.8-1 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.8.2 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 415ms :: artifacts dl 127ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.8-1 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.6.0 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.1 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.1 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.8.2 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-54434320-058a-4a51-8295-d57d116486f0
	confs: [default]
	0 artifacts copied, 9 already retrieved (0kB/16ms)
22/06/11 18:08:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/11 18:08:27 INFO SparkContext: Running Spark version 3.2.1
22/06/11 18:08:27 INFO ResourceUtils: ==============================================================
22/06/11 18:08:27 INFO ResourceUtils: No custom resources configured for spark.driver.
22/06/11 18:08:27 INFO ResourceUtils: ==============================================================
22/06/11 18:08:27 INFO SparkContext: Submitted application: Evaluate-Human-Balance
22/06/11 18:08:27 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/06/11 18:08:27 INFO ResourceProfile: Limiting resource is cpu
22/06/11 18:08:27 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/06/11 18:08:27 INFO SecurityManager: Changing view acls to: spark
22/06/11 18:08:27 INFO SecurityManager: Changing modify acls to: spark
22/06/11 18:08:27 INFO SecurityManager: Changing view acls groups to: 
22/06/11 18:08:27 INFO SecurityManager: Changing modify acls groups to: 
22/06/11 18:08:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
22/06/11 18:08:27 INFO Utils: Successfully started service 'sparkDriver' on port 44843.
22/06/11 18:08:27 INFO SparkEnv: Registering MapOutputTracker
22/06/11 18:08:27 INFO SparkEnv: Registering BlockManagerMaster
22/06/11 18:08:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/11 18:08:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/11 18:08:27 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/06/11 18:08:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-51a60201-76e2-4303-a9fe-c1405721485c
22/06/11 18:08:28 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/06/11 18:08:28 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/11 18:08:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/11 18:08:28 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://d86e382532b9:4040
22/06/11 18:08:28 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar at spark://d86e382532b9:44843/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar at spark://d86e382532b9:44843/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar at spark://d86e382532b9:44843/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://d86e382532b9:44843/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://d86e382532b9:44843/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar at spark://d86e382532b9:44843/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://d86e382532b9:44843/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar at spark://d86e382532b9:44843/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://d86e382532b9:44843/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:08:28 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:08:28 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.apache.kafka_kafka-clients-2.6.0.jar
22/06/11 18:08:28 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 18:08:28 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.spark-project.spark_unused-1.0.0.jar
22/06/11 18:08:28 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar at file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/com.github.luben_zstd-jni-1.4.8-1.jar
22/06/11 18:08:28 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.lz4_lz4-java-1.7.1.jar
22/06/11 18:08:28 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.xerial.snappy_snappy-java-1.1.8.2.jar
22/06/11 18:08:28 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 18:08:28 INFO Executor: Starting executor ID driver on host d86e382532b9
22/06/11 18:08:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.xerial.snappy_snappy-java-1.1.8.2.jar
22/06/11 18:08:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:08:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/com.github.luben_zstd-jni-1.4.8-1.jar
22/06/11 18:08:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:08:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 18:08:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.spark-project.spark_unused-1.0.0.jar
22/06/11 18:08:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.lz4_lz4-java-1.7.1.jar
22/06/11 18:08:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.apache.kafka_kafka-clients-2.6.0.jar
22/06/11 18:08:28 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 18:08:28 INFO Executor: Fetching spark://d86e382532b9:44843/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO TransportClientFactory: Successfully created connection to d86e382532b9/172.22.0.4:44843 after 18 ms (0 ms spent in bootstraps)
22/06/11 18:08:28 INFO Utils: Fetching spark://d86e382532b9:44843/jars/com.github.luben_zstd-jni-1.4.8-1.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp3036606043467410413.tmp
22/06/11 18:08:28 INFO Utils: /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp3036606043467410413.tmp has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/com.github.luben_zstd-jni-1.4.8-1.jar
22/06/11 18:08:28 INFO Executor: Adding file:/tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/com.github.luben_zstd-jni-1.4.8-1.jar to class loader
22/06/11 18:08:28 INFO Executor: Fetching spark://d86e382532b9:44843/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Fetching spark://d86e382532b9:44843/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp182633177004875761.tmp
22/06/11 18:08:28 INFO Utils: /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp182633177004875761.tmp has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.spark-project.spark_unused-1.0.0.jar
22/06/11 18:08:28 INFO Executor: Adding file:/tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.spark-project.spark_unused-1.0.0.jar to class loader
22/06/11 18:08:28 INFO Executor: Fetching spark://d86e382532b9:44843/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Fetching spark://d86e382532b9:44843/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp7498153227807720138.tmp
22/06/11 18:08:28 INFO Utils: /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp7498153227807720138.tmp has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.xerial.snappy_snappy-java-1.1.8.2.jar
22/06/11 18:08:28 INFO Executor: Adding file:/tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.xerial.snappy_snappy-java-1.1.8.2.jar to class loader
22/06/11 18:08:28 INFO Executor: Fetching spark://d86e382532b9:44843/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Fetching spark://d86e382532b9:44843/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp2314507383310425776.tmp
22/06/11 18:08:28 INFO Utils: /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp2314507383310425776.tmp has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:08:28 INFO Executor: Adding file:/tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar to class loader
22/06/11 18:08:28 INFO Executor: Fetching spark://d86e382532b9:44843/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Fetching spark://d86e382532b9:44843/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp7540301783098029164.tmp
22/06/11 18:08:28 INFO Utils: /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp7540301783098029164.tmp has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar
22/06/11 18:08:28 INFO Executor: Adding file:/tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar to class loader
22/06/11 18:08:28 INFO Executor: Fetching spark://d86e382532b9:44843/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Fetching spark://d86e382532b9:44843/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp8665127203130780844.tmp
22/06/11 18:08:28 INFO Utils: /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp8665127203130780844.tmp has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.apache.commons_commons-pool2-2.6.2.jar
22/06/11 18:08:28 INFO Executor: Adding file:/tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.apache.commons_commons-pool2-2.6.2.jar to class loader
22/06/11 18:08:28 INFO Executor: Fetching spark://d86e382532b9:44843/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Fetching spark://d86e382532b9:44843/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp8902037151721364417.tmp
22/06/11 18:08:28 INFO Utils: /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp8902037151721364417.tmp has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.lz4_lz4-java-1.7.1.jar
22/06/11 18:08:28 INFO Executor: Adding file:/tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.lz4_lz4-java-1.7.1.jar to class loader
22/06/11 18:08:28 INFO Executor: Fetching spark://d86e382532b9:44843/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Fetching spark://d86e382532b9:44843/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp928374699244243519.tmp
22/06/11 18:08:28 INFO Utils: /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp928374699244243519.tmp has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.slf4j_slf4j-api-1.7.30.jar
22/06/11 18:08:28 INFO Executor: Adding file:/tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.slf4j_slf4j-api-1.7.30.jar to class loader
22/06/11 18:08:28 INFO Executor: Fetching spark://d86e382532b9:44843/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1654970907649
22/06/11 18:08:28 INFO Utils: Fetching spark://d86e382532b9:44843/jars/org.apache.kafka_kafka-clients-2.6.0.jar to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp2966978255095755491.tmp
22/06/11 18:08:28 INFO Utils: /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/fetchFileTemp2966978255095755491.tmp has been previously copied to /tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.apache.kafka_kafka-clients-2.6.0.jar
22/06/11 18:08:28 INFO Executor: Adding file:/tmp/spark-fa1292e5-c54d-45e8-98bd-aac4dddea697/userFiles-c77446a2-93a7-4a5e-962e-d398f9902d48/org.apache.kafka_kafka-clients-2.6.0.jar to class loader
22/06/11 18:08:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43515.
22/06/11 18:08:28 INFO NettyBlockTransferService: Server created on d86e382532b9:43515
22/06/11 18:08:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/11 18:08:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d86e382532b9, 43515, None)
22/06/11 18:08:28 INFO BlockManagerMasterEndpoint: Registering block manager d86e382532b9:43515 with 366.3 MiB RAM, BlockManagerId(driver, d86e382532b9, 43515, None)
22/06/11 18:08:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d86e382532b9, 43515, None)
22/06/11 18:08:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d86e382532b9, 43515, None)
22/06/11 18:08:28 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/06/11 18:08:28 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
22/06/11 18:08:31 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
^CERROR:root:Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
RuntimeError: reentrant call inside <_io.BufferedReader name=3>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
ERROR:root:Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/opt/bitnami/python/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 292, in signal_handler
    self.cancelAllJobs()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 1195, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
    return f(*a, **kw)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o14.sc

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
Traceback (most recent call last):
  File "/home/workspace/sparkpykafkajoin.py", line 200, in <module>
    customerRiskStreamingDF.selectExpr("to_json(struct(*)) AS value")\
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming.py", line 101, in awaitTermination
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 334, in get_return_value
py4j.protocol.Py4JError: An error occurred while calling o98.awaitTermination
